1
00:00:00,090 --> 00:00:02,430
Konten berikut diberikan
di bawah lisensi

2
00:00:02,430 --> 00:00:03,820
Creative Commons.

3
00:00:03,820 --> 00:00:06,050
Dukungan Anda akan membantu
MIT OpenCourseWare

4
00:00:06,050 --> 00:00:10,150
untuk terus menyediakan bahan edukasi
berkualitas tinggi secara gratis

5
00:00:10,150 --> 00:00:12,690
Untuk berdonasi, atau
melihat materi tambahan

6
00:00:12,690 --> 00:00:16,600
dari ratusan kuliah MIT,
kunjungi MIT OpenCourseWare

7
00:00:16,600 --> 00:00:26,054
di ocw.mit.edu.

8
00:00:26,054 --> 00:00:27,720
PROFESSOR: Di kelas
ini, semester ini,

9
00:00:27,720 --> 00:00:29,696
Dosen lain yang
akan mengajar adalah


10
00:00:29,696 --> 00:00:32,070
James Mickens, profesor yang
berkunjung dari Microsoft

11
00:00:32,070 --> 00:00:33,480
Research.

12
00:00:33,480 --> 00:00:36,130
Beliau akan mengajarkan beberapa
topik lain seperti keamanan web

13
00:00:36,130 --> 00:00:37,520
nantinya.

14
00:00:37,520 --> 00:00:40,500
Tapi kita akan memutuskan belakangan
apa yang akan terjadi sebenarnya, dalam hal

15
00:00:40,500 --> 00:00:41,600
pembagian kuliah.

16
00:00:41,600 --> 00:00:46,120
Kita juga punya empat asisten tahun ini,
Stephen, Webb, [TIDAK TERDENGAR],

17
00:00:46,120 --> 00:00:47,610
dan James.

18
00:00:47,610 --> 00:00:52,590
Dan semoga Anda akan menemui mereka
di jam kerja selama tahun ini

19
00:00:52,590 --> 00:00:54,780
jika Anda membutuhkan bantuan.

20
00:00:54,780 --> 00:00:57,950
Jadi rencana untuk kelas ini
adalah untuk memahami

21
00:00:57,950 --> 00:01:01,900
bagaimana membuat sistem yang aman,
mengapa sistem komputer terkadang

22
00:01:01,900 --> 00:01:04,330
tidak aman dan bagaimana
kita dapat membuatnya aman,

23
00:01:04,330 --> 00:01:06,040
dan apa yang salah.

24
00:01:06,040 --> 00:01:08,970
Dan untuk melakukan ini, tidak ada
buku teks yang benar-benar bagus

25
00:01:08,970 --> 00:01:09,830
tentang topik ini.

26
00:01:09,830 --> 00:01:11,246
Jadi gantinya, apa
yang akan kita lakukan

27
00:01:11,246 --> 00:01:13,690
adalah, setiap kuliah
selain yang ini

28
00:01:13,690 --> 00:01:16,860
akan berfokus pada beberapa
penelitian, biasanya paper,

29
00:01:16,860 --> 00:01:19,730
di mana kami akan menaruhnya
pada situs web dan Anda

30
00:01:19,730 --> 00:01:21,050
perlu membacanya sebelum pertemuan.

31
00:01:21,050 --> 00:01:22,550
Dan ada beberapa
pertanyaan yang perlu

32
00:01:22,550 --> 00:01:25,780
Anda jawab di sistem pengumpulan
terkait papernya.

33
00:01:25,780 --> 00:01:28,520
Dan berikan pertanyaan Anda
sebelum pukul 10 malam, 1 hari

34
00:01:28,520 --> 00:01:29,220
sebelum kuliah.

35
00:01:29,220 --> 00:01:30,110
Dan jika Anda datang
ke pertemuan kuliah,

36
00:01:30,110 --> 00:01:31,984
kita akan mendiskusikan
papernya, mencoba memahami,

37
00:01:31,984 --> 00:01:32,810
bagaimanakah sistemnya?

38
00:01:32,810 --> 00:01:34,500
Masalah apa yang diselesaikan?

39
00:01:34,500 --> 00:01:35,300
Kapan itu bisa bekerja?

40
00:01:35,300 --> 00:01:36,730
Kapan tidak bisa bekerja?

41
00:01:36,730 --> 00:01:39,000
Apakah ide-ide ini
bagus untuk kasus lain?

42
00:01:39,000 --> 00:01:39,560
Dan lain-lain.

43
00:01:39,560 --> 00:01:41,840
Dan semoga, melalui
studi kasus-studi kasus ini,

44
00:01:41,840 --> 00:01:45,080
kita dapat mengapresiasi tentang
bagaimana kita membangun

45
00:01:45,080 --> 00:01:47,220
sistem yang aman.

46
00:01:47,220 --> 00:01:49,644
Dan kita punya beberapa jadwal
di awal yang bisa dilihat di situs web.

47
00:01:49,644 --> 00:01:52,310
Jika ada topik lain di mana
Anda tertarik,

48
00:01:52,310 --> 00:01:54,300
atau jika ada paper tertentu
Anda yang menarik perhatian Anda,

49
00:01:54,300 --> 00:01:56,050
kirimkan kami email dan
kita akan lihat apakah kita bisa

50
00:01:56,050 --> 00:01:57,530
memasukkannya ke dalam materi.

51
00:01:57,530 --> 00:01:59,150
Kami cukup fleksibel.

52
00:01:59,150 --> 00:02:01,150
Jadi jika ada
sesuatu yang ingin

53
00:02:01,150 --> 00:02:03,973
Anda dengar,
beritahu kami.

54
00:02:03,973 --> 00:02:08,520
Selain itu, jika Anda
punya pertanyaan

55
00:02:08,520 --> 00:02:11,290
atau ada kesalahan,
potong saja dan bertanya

56
00:02:11,290 --> 00:02:15,760
kepada kami di
kuliah, kapan saja.

57
00:02:15,760 --> 00:02:18,190
Keamanan adalah, dalam banyak varian,
hanyalah tentang detail,

58
00:02:18,190 --> 00:02:20,100
dan memastikan semuanya benar.

59
00:02:20,100 --> 00:02:21,742
Dan saya pasti akan
melakukan kesalahan.

60
00:02:21,742 --> 00:02:23,200
Jadi jika sesuatu
terlihat tidak benar,

61
00:02:23,200 --> 00:02:24,570
kemungkinan besar memang ada yang salah.

62
00:02:24,570 --> 00:02:26,153
Dan Anda dapat
memotong dan bertanya.

63
00:02:26,153 --> 00:02:28,040
Dan kita akan melihat
apa yang terjadi

64
00:02:28,040 --> 00:02:30,730
dan bagaimana cara yang
benar untuk melakukan sesuatu.

65
00:02:30,730 --> 00:02:33,670
Dan saya rasa dalam hal
pengelolaan kelas,

66
00:02:33,670 --> 00:02:35,136
bagian besar lain
dari kelasnya,

67
00:02:35,136 --> 00:02:36,510
selain dari
kuliah mimbar, adalah

68
00:02:36,510 --> 00:02:38,540
deretan tugas-tugas
lab.

69
00:02:38,540 --> 00:02:40,740
Yang pertama sudah
dimunculkan di situs web.

70
00:02:40,740 --> 00:02:42,960
Dan tugas-tugas lab
ini akan membantu

71
00:02:42,960 --> 00:02:46,840
Anda dalam memahami
berbagai jenis masalah

72
00:02:46,840 --> 00:02:51,220
keamanan dan bagaimana Anda
mencegahnya pada server web sederhana.

73
00:02:51,220 --> 00:02:54,136
Jadi di lab pertama, di mana
sudah dimunculkan saat ini,

74
00:02:54,136 --> 00:02:55,510
Anda akan mengambil
sebuah server web

75
00:02:55,510 --> 00:02:58,910
yang kami berikan kepada Anda dan mencari
cara-cara untuk mengeksploitasi celah keamanan

76
00:02:58,910 --> 00:03:01,800
buffer verflow di dalamnya dan
mengambil alih kontrol situs web ini

77
00:03:01,800 --> 00:03:04,020
hanya dengan mengirimkan
paket dan permintaan yang dibuat

78
00:03:04,020 --> 00:03:05,430
sedemikian rupa.

79
00:03:05,430 --> 00:03:07,300
Dan pada lab-lab yang lain,
Anda akan melihat beberapa cara

80
00:03:07,300 --> 00:03:10,150
untuk mempertahankan server web,
untuk menemukan bug di kode

81
00:03:10,150 --> 00:03:13,910
untuk menulis worm yang
berjalan di peramban

82
00:03:13,910 --> 00:03:18,920
pengguna, dan jenis-jenis lain
dari permasalahan keamanan yang menarik.

83
00:03:18,920 --> 00:03:21,150
Satu hal yang mengejutkan
banyak mahasiswa

84
00:03:21,150 --> 00:03:24,740
adalah setiap lab menggunakan
bahasa yang berbeda.

85
00:03:24,740 --> 00:03:27,160
Jadi lab pertama menggunakan
bahasa C dan Assembly.

86
00:03:27,160 --> 00:03:29,530
Lab kedua melibatkan banyak
pemrograman Python.

87
00:03:29,530 --> 00:03:30,980
Lab ketiga tentang
hal lain lagi.

88
00:03:30,980 --> 00:03:32,660
Lab kelima tentang JavaScript.

89
00:03:32,660 --> 00:03:33,600
Dan seterusnya.

90
00:03:33,600 --> 00:03:35,340
Hal ini tidak bisa dihindari.

91
00:03:35,340 --> 00:03:36,920
Dan saya ingin
meminta maaf di awal

92
00:03:36,920 --> 00:03:37,970
karena Anda akan
perlu mempelajari

93
00:03:37,970 --> 00:03:40,179
bahasa-bahasa ini jika sebelum ini
Anda belum pernah melihatnya.

94
00:03:40,179 --> 00:03:42,178
Dari sudut pandang tertentu itu akan berguna,
karena dunia nyata

95
00:03:42,178 --> 00:03:42,740
adalah seperti ini.

96
00:03:42,740 --> 00:03:44,573
Semua sistem kompleks
dan dibangun

97
00:03:44,573 --> 00:03:45,550
dari bermacam-macam bagian.

98
00:03:45,550 --> 00:03:48,149
Dan pada jangka panjang,
akan berguna bagi Anda,

99
00:03:48,149 --> 00:03:49,690
untuk karakter moral
Anda atau apapun itu,

100
00:03:49,690 --> 00:03:52,180
untuk mempelajari hal-hal ini.

101
00:03:52,180 --> 00:03:53,871
Tapi hal itu akan membutuhkan
persiapan tertentu,

102
00:03:53,871 --> 00:03:56,120
terutama jika Anda belum pernah
melihat bahasa-bahasa ini sebelumnya.

103
00:03:56,120 --> 00:03:57,790
Akan membantu jika
Anda memulai lebih awal.

104
00:03:57,790 --> 00:04:00,750
Terutama, lab
pertama akan bergantung pada

105
00:04:00,750 --> 00:04:03,130
banyak detail dari
kode bahasa C dan Assembly

106
00:04:03,130 --> 00:04:06,040
yang mana tidak diajarkan
di kelas-kelas lain

107
00:04:06,040 --> 00:04:07,560
di sini secara mendetail.

108
00:04:07,560 --> 00:04:09,400
Jadi mungkin ide yang
baik untuk mulai lebih awal.

109
00:04:09,400 --> 00:04:12,290
Dan kami akan mencoba untuk memastikan
asisten untuk mempersiapkan waktu konsultasi minggu depan

110
00:04:12,290 --> 00:04:14,700
di mana kita akan melakukan
sesi tutorial

111
00:04:14,700 --> 00:04:18,700
di mana kita dapat membantu Anda
memulai dengan memahami

112
00:04:18,700 --> 00:04:21,500
seperti apa bentuk program biner,
bagaimana untuk memecahnya,

113
00:04:21,500 --> 00:04:25,900
bagaimana untuk mengetahui
apa yang ada di stack, dan seterusnya.

114
00:04:25,900 --> 00:04:26,790
Baiklah.

115
00:04:26,790 --> 00:04:29,259
Dan saya rasa hal
lainnya, kita akan

116
00:04:29,259 --> 00:04:30,550
merekam kuliah-kuliah di tahun ini.

117
00:04:30,550 --> 00:04:33,030
Jadi Anda mungkin akan
bisa melihatnya secara daring.

118
00:04:33,030 --> 00:04:35,030
Kami akan mengumumkannya setelah
kami sendiri mendapatkannya

119
00:04:35,030 --> 00:04:37,690
dari mereka di bagian video.

120
00:04:37,690 --> 00:04:39,340
Dan bagian terakhir
dari administrivia

121
00:04:39,340 --> 00:04:42,777
adalah Anda harus, jika
Anda memiliki pertanyaan daring,

122
00:04:42,777 --> 00:04:44,360
kita menggunakan Piazza,
jadi saya yakin Anda sudah

123
00:04:44,360 --> 00:04:46,870
menggunakannya di kelas-kelas lain.

124
00:04:46,870 --> 00:04:47,530
Baiklah.

125
00:04:47,530 --> 00:04:51,020
Jadi sebelum kita menyelam ke dalam topik keamanan,
Saya perlu memberi tahu Anda satu hal.

126
00:04:51,020 --> 00:04:55,190
Ada beberapa peraturan
dari MIT untuk mengakses

127
00:04:55,190 --> 00:04:58,030
jaringan MIT saat Anda,
terutama, melakukan penelitian

128
00:04:58,030 --> 00:05:00,180
keamanan atau bermain-main
dengan masalah keamanan,

129
00:05:00,180 --> 00:05:03,200
Anda harus tahu bahwa tidak semua
yang secara teknis dapat Anda

130
00:05:03,200 --> 00:05:04,870
lakukan itu legal.

131
00:05:04,870 --> 00:05:08,450
Dan ada banyak hal yang akan
Anda pelajari di kelas ini

132
00:05:08,450 --> 00:05:09,580
yang secara teknis memungkinkan.

133
00:05:09,580 --> 00:05:13,880
Kita akan memahami bagaimana
sistem dapat rusak atau dirusak.

134
00:05:13,880 --> 00:05:16,650
Bukan berarti Anda perlu
keluar dan melakukannya dimanapun.

135
00:05:16,650 --> 00:05:19,370
Dan ada tautan ini pada
catatan kuliah

136
00:05:19,370 --> 00:05:22,290
kami akan mengumumkan itu di mana
ada aturan-aturan dan arahan-arahan yang baik.

137
00:05:22,290 --> 00:05:24,060
Secara umum, jika
Anda tidak yakin,

138
00:05:24,060 --> 00:05:28,950
tanyalah salah satu dosen atau asisten
tentang apa yang seharusnya Anda lakukan.

139
00:05:28,950 --> 00:05:34,800
Dan semoga itu tidak terlalu
membingungkan, apa yang terjadi.

140
00:05:34,800 --> 00:05:35,300
Baiklah.

141
00:05:35,300 --> 00:05:37,290
Adakah pertanyaan tentang
administrivia-administrivia ini

142
00:05:37,290 --> 00:05:39,620
sebelum kita menyelam lebih dalam?

143
00:05:39,620 --> 00:05:42,150
Jangan ragu untuk bertanya.

144
00:05:42,150 --> 00:05:42,990
OK.

145
00:05:42,990 --> 00:05:44,290
Apa itu keamanan?

146
00:05:44,290 --> 00:05:47,240
Jadi kita akan mulai dengan
hal-hal dasar hari ini.

147
00:05:47,240 --> 00:05:50,150
Dan kita akan melihat
beberapa contoh umum

148
00:05:50,150 --> 00:05:53,280
tentang bagaimana keamanan itu
sulit dan apa artinya untuk mencoba

149
00:05:53,280 --> 00:05:55,160
membangun sistem yang aman.

150
00:05:55,160 --> 00:05:56,770
Karena tidak benar-benar
ada paper,

151
00:05:56,770 --> 00:05:59,930
ini mungkin tidak akan mengandung
konten intelektual yang dalam, mungkin,

152
00:05:59,930 --> 00:06:02,180
tapi itu akan memberikan sedikit
latar belakang dan konteks tentang bagaimana

153
00:06:02,180 --> 00:06:04,550
berpikir tentang sistem yang aman.

154
00:06:04,550 --> 00:06:06,890
Jadi keamanan, secara
umum, adalah tentang

155
00:06:06,890 --> 00:06:10,755
mencapai beberapa tujuan ketika
ada musuh yang hadir.

156
00:06:13,410 --> 00:06:16,510
Jadi anggap saja seperti ada beberapa
orang jahat di luar sana yang ingin

157
00:06:16,510 --> 00:06:18,520
memastikan bahwa Anda tidak berhasil.

158
00:06:18,520 --> 00:06:19,770
Mereka ingin mencuri berkas Anda.

159
00:06:19,770 --> 00:06:22,450
Mereka ingin menghapus keseluruhan
isi dari hard drive Anda.

160
00:06:22,450 --> 00:06:24,710
Mereka ingin memastikan bahwa
tidak ada yang bekerja

161
00:06:24,710 --> 00:06:27,770
dan telepon Anda tidak tersambung,
semua hal ini, benar kan?

162
00:06:27,770 --> 00:06:30,130
Dan sebuah sistem yang aman adalah
sebuah sistem yang dapat

163
00:06:30,130 --> 00:06:32,650
melakukan sesuatu, terlepas dari
apa yang orang jahat tersebut

164
00:06:32,650 --> 00:06:33,492
sedang coba lakukan terhadap Anda.

165
00:06:33,492 --> 00:06:35,950
Jadi cukup keren ketika kita sebenarnya
berpotensi untuk membuat

166
00:06:35,950 --> 00:06:39,000
sistem yang tangguh
dari seluruh jangkauan

167
00:06:39,000 --> 00:06:41,400
orang jahat,
musuh, penyerang,

168
00:06:41,400 --> 00:06:43,440
apapun panggilan Anda untuk mereka.

169
00:06:43,440 --> 00:06:45,720
Dan kita masih dapat membuat
sistem komputer yang

170
00:06:45,720 --> 00:06:48,010
memudahkan kita dalam menyelesaikan tugas kita.

171
00:06:48,010 --> 00:06:53,430
Dan cara umum untuk
berpikir tentang keamanan

172
00:06:53,430 --> 00:06:55,880
adalah dengan memecahnya
menjadi tiga bagian.

173
00:06:55,880 --> 00:07:00,064
Satu bagian adalah kurang lebih
kebijakan yang Anda

174
00:07:00,064 --> 00:07:01,230
ingin Anda terapkan pada sistem Anda.

175
00:07:01,230 --> 00:07:03,313
Ini adalah tujuan 
yang Anda ingin capai.

176
00:07:03,313 --> 00:07:05,430
Seperti yah, mungkin,
hanya saya yang seharusnya

177
00:07:05,430 --> 00:07:09,190
dapat membaca
berkas nilai untuk 6.858.

178
00:07:09,190 --> 00:07:11,330
Atau mungkin TA juga,
dan seluruh rekan pengajar,

179
00:07:11,330 --> 00:07:11,979
dan sebagainya.

180
00:07:11,979 --> 00:07:14,270
Namun ada beberapa ketentuan
mengenai apa yang sistem saya 

181
00:07:14,270 --> 00:07:16,210
dapat lakukan.

182
00:07:16,210 --> 00:07:18,466
Dan kemudian, jika Anda 
ingin berpikir

183
00:07:18,466 --> 00:07:20,340
tentang kebijakan seperti apa
yang mungkin Anda tuliskan,

184
00:07:20,340 --> 00:07:26,850
secara umum berkaitan dengan
kerahasiaan data,

185
00:07:26,850 --> 00:07:31,040
jadi berkas nilai hanya dapat
diakses oleh

186
00:07:31,040 --> 00:07:32,330
staf dari kuliah 6.858.

187
00:07:32,330 --> 00:07:33,890
Contoh lain dari
kebijakan keamanan

188
00:07:33,890 --> 00:07:35,744
berkaitan
dengan integritas.

189
00:07:35,744 --> 00:07:37,160
Sebagai contoh, hanya
staf kuliah

190
00:07:37,160 --> 00:07:38,604
yang dapat mengubah berkas nilai.

191
00:07:38,604 --> 00:07:40,770
Atau hanya staf kursus
yang dapat mengunggah nilai akhir

192
00:07:40,770 --> 00:07:41,853
ke bagian kantor bagian akademik.

193
00:07:41,853 --> 00:07:43,290
Itu akan sangat bagus.

194
00:07:43,290 --> 00:07:47,770
Lalu kalian juga dapat memikirkan tentang  
hal seperti ketersediaan.

195
00:07:47,770 --> 00:07:51,770
Jadi misalnya, sebuah situs web
harus tetap tersedia

196
00:07:51,770 --> 00:07:54,040
meskipun ada orang jahat yang mencoba
untuk membuatnya mati dan melancarkan

197
00:07:54,040 --> 00:07:57,972
serangan semacam DOS-- Denial of Service--
terhadap situs web tersebut.

198
00:07:57,972 --> 00:07:59,180
Berarti situs web ini baik dan bagus.

199
00:07:59,180 --> 00:08:01,180
Jadi ini merupakan beberapa kebijakan
yang mungkin harus kita

200
00:08:01,180 --> 00:08:02,860
perhatikan dari suatu sistem.

201
00:08:02,860 --> 00:08:05,220
Namun karena ini tentang keamanan,
maka ada orang jahat yang terlibat di dalamnya.

202
00:08:05,220 --> 00:08:06,680
Kita harus mengerti,
menurut kita

203
00:08:06,680 --> 00:08:07,980
apa yang orang jahat itu akan lakukan?

204
00:08:07,980 --> 00:08:10,190
Dan inilah yang biasanya
kita sebut sebagai model ancaman (threat model).

205
00:08:13,090 --> 00:08:15,130
Dan ini pada dasarnya
hanyalah sekumpulan asumsi

206
00:08:15,130 --> 00:08:23,090
tentang orang jahat atau musuh itu.

207
00:08:23,090 --> 00:08:25,710
Dan penting untuk memiliki
beberapa asumsi

208
00:08:25,710 --> 00:08:29,310
tentang orang jahat karena,
jika orang jahat ada di mana-mana

209
00:08:29,310 --> 00:08:32,700
dan di setiap tempat pada satu waktu yang sama
dan kalian dapat melakukan apapun yang mereka inginkan,

210
00:08:32,700 --> 00:08:36,030
akan sulit untuk mendapatkan
keamanan yang serupa.

211
00:08:36,030 --> 00:08:37,630
Jadi sebagai contoh,
mungkin kalian ingin

212
00:08:37,630 --> 00:08:40,750
menganggap bahwa orang jahat tersebut
tidak mengetahui password Anda,

213
00:08:40,750 --> 00:08:43,159
atau mereka sebenarnya tidak memiliki
akses secara fisik ke telepon Anda

214
00:08:43,159 --> 00:08:45,050
dan kunci Anda dan laptop Anda.

215
00:08:45,050 --> 00:08:47,990
Jika tidak, akan sulit
untuk membuat semacam kemajuan

216
00:08:47,990 --> 00:08:50,510
dalam permainan ini.

217
00:08:50,510 --> 00:08:52,940
Dan ternyata walaupun hal ini
sebenarnya cukup sulit

218
00:08:52,940 --> 00:08:56,470
untuk diselesaikan, tapi saya kira
sebuah aturan umum itu

219
00:08:56,470 --> 00:08:59,390
akan lebih baik jika berada di
sisi yang lebih aman dan

220
00:08:59,390 --> 00:09:01,800
konservatif dalam memilih
model ancaman Anda,

221
00:09:01,800 --> 00:09:03,920
karena orang jahat mungkin
selalu mengejutkan Anda

222
00:09:03,920 --> 00:09:07,290
dengan apa yang mereka mungkin
dapat lakukan dalam praktiknya.

223
00:09:07,290 --> 00:09:10,190
Dan akhirnya, untuk
mencapai keamanan, untuk

224
00:09:10,190 --> 00:09:12,980
mencapai tujuan kita dengan
sekumpulan asumsi tersebut,

225
00:09:12,980 --> 00:09:14,580
kita akan melihat
beberapa mekanisme.

226
00:09:17,400 --> 00:09:21,720
Dan ini adalah, pada dasarnya,
perangkat lunak atau perangkat keras

227
00:09:21,720 --> 00:09:24,590
atau bagian apapun
dari rancangan sistem,

228
00:09:24,590 --> 00:09:26,280
implementasi,
dan lain-lain, hal tersebut

229
00:09:26,280 --> 00:09:30,470
akan mencoba memastikan bahwa
kebijakan kita diikuti

230
00:09:30,470 --> 00:09:34,430
selama orang jahat
mengikuti model ancamannya.

231
00:09:34,430 --> 00:09:36,970
Jadi hasil akhirnya
adalah bahwa, selama

232
00:09:36,970 --> 00:09:39,700
model ancaman kita tepat,
semoga kita akan

233
00:09:39,700 --> 00:09:40,810
memenuhi kebijakan kita.

234
00:09:40,810 --> 00:09:44,100
Dan hal itu harus menjadi kasus di mana
mekanismenya tidak gagal.

235
00:09:44,100 --> 00:09:45,420
Masuk akal?

236
00:09:45,420 --> 00:09:48,220
Cerita yang cukup umum
tentang bagaimana

237
00:09:48,220 --> 00:09:50,470
untuk memikirkan
hal semacam ini.

238
00:09:50,470 --> 00:09:52,410
Jadi kenapa ini sangat sulit, yah?

239
00:09:52,410 --> 00:09:53,644
Ini terlihat seperti sebuah rencana yang sederhana.

240
00:09:53,644 --> 00:09:55,060
Anda menuliskan
tiga hal ini,

241
00:09:55,060 --> 00:09:57,180
dan Anda bisa memulainya.

242
00:09:57,180 --> 00:10:02,180
Namun praktiknya, seperti Anda, saya
yakin, pernah melihat di dunia ini,

243
00:10:02,180 --> 00:10:04,490
sistem komputer hampir
selalu bisa diserang

244
00:10:04,490 --> 00:10:05,730
dalam satu cara atau lainnya.

245
00:10:05,730 --> 00:10:08,300
Dan pembobolan
cukup lumrah.

246
00:10:08,300 --> 00:10:12,210
Dan alasan utama
mengapa keamanan

247
00:10:12,210 --> 00:10:14,800
menjadi masalah yang sulit adalah
karena apa yang kita miliki di sini

248
00:10:14,800 --> 00:10:17,260
adalah semacam, ini akan
terdengar tidak asing bagi Anda

249
00:10:17,260 --> 00:10:19,400
yang sudah mengambil kuliah 6.033, ini
adalah tujuan negatif,

250
00:10:19,400 --> 00:10:23,270
artinya kita harus memastikan
kebijakan keamanan kita

251
00:10:23,270 --> 00:10:27,360
dipatuhi terlepas dari apa yang
dapat dilakukan oleh penyerang.

252
00:10:27,360 --> 00:10:30,730
Jadi sebaliknya, jika Anda
ingin membangun sebuah berkas sistem,

253
00:10:30,730 --> 00:10:36,310
dan Anda ingin memastikan bahwa
asisten-asisten saya dapat mengakses

254
00:10:36,310 --> 00:10:37,790
berkas nilai, itu sangat mudah.

255
00:10:37,790 --> 00:10:40,120
Saya hanya perlu menanyakan mereka, hei, bisakah
kalian menguji dan melihat?

256
00:10:40,120 --> 00:10:41,411
Dapatkah Anda mengakses berkas nilai?

257
00:10:41,411 --> 00:10:43,600
Dan jika mereka semua 
dapat mengaksesnya, selesai.

258
00:10:43,600 --> 00:10:45,340
Sistem tersebut bekerja.

259
00:10:45,340 --> 00:10:48,070
Namun jika saya ingin mengatakan bahwa
tidak ada orang lain selain asisten-asisten

260
00:10:48,070 --> 00:10:50,640
yang dapat mengakses berkas nilai,
ini adalah masalah yang lebih sulit

261
00:10:50,640 --> 00:10:52,820
untuk diselesaikan, karena sekarang
saya harus mencari tahu

262
00:10:52,820 --> 00:10:56,010
apa yang bisa dilakukan semua orang selain asisten
di seluruh dunia untuk mencoba

263
00:10:56,010 --> 00:10:57,460
mendapatkan berkas nilai saya, benar?

264
00:10:57,460 --> 00:11:01,110
Mereka bisa mencoba untuk
membuka dan melihatnya.

265
00:11:01,110 --> 00:11:02,960
Mungkin sistem berkas saya
akan melarangnya.

266
00:11:02,960 --> 00:11:04,900
Namun mereka mungkin mencoba semua
jenis serangan yang lain,

267
00:11:04,900 --> 00:11:07,060
seperti menebak
password untuk para asisten

268
00:11:07,060 --> 00:11:10,670
atau mencuri laptop milik asisten
atau membobol ruangan

269
00:11:10,670 --> 00:11:11,960
atau siapa yang tahu, benar?

270
00:11:11,960 --> 00:11:14,010
Ini adalah semua hal yang
kita harus benar-benar tempatkan

271
00:11:14,010 --> 00:11:15,050
ke dalam model ancaman kita.

272
00:11:15,050 --> 00:11:17,650
Mungkin untuk kelas ini,
saya tidak perlu terlalu khawatir tentang

273
00:11:17,650 --> 00:11:21,280
berkas nilai, untuk khawatir tentang
laptop orang-orang ini yang

274
00:11:21,280 --> 00:11:22,880
dicuri dari kamar asrama mereka.

275
00:11:22,880 --> 00:11:23,460
Meskipun mungkin saya perlu khawatir.

276
00:11:23,460 --> 00:11:24,001
Saya tidak tahu.

277
00:11:24,001 --> 00:11:25,140
Sulit untuk mengatakannya, benar?

278
00:11:25,140 --> 00:11:27,700
Dan akibatnya,
permainan keamanan ini

279
00:11:27,700 --> 00:11:30,030
seringkali tidak begitu
jelas seperti halnya

280
00:11:30,030 --> 00:11:32,884
membuat sekumpulan asumsi
yang tepat.

281
00:11:32,884 --> 00:11:35,050
Dan berdasarkan fakta yang
sering Anda sering sadari,

282
00:11:35,050 --> 00:11:37,000
sebaiknya Anda berpikir
tentang hal itu.

283
00:11:39,520 --> 00:11:40,720
Baiklah.

284
00:11:40,720 --> 00:11:42,700
Dan semacamnya, sebagai
konsekuensinya, ini adalah

285
00:11:42,700 --> 00:11:44,170
sebuah proses yang iteratif.

286
00:11:44,170 --> 00:11:46,960
Dan hal yang Anda akhirnya
sadari di setiap iterasi

287
00:11:46,960 --> 00:11:49,132
adalah, baiklah, inilah
celah terlemah ke dalam sistem saya.

288
00:11:49,132 --> 00:11:50,590
Mungkin saya mendapatkan
model ancaman yang salah.

289
00:11:50,590 --> 00:11:53,290
Mungkin mekanisme saya memiliki beberapa bug
di dalamnya karena itu adalah sebuah perangkat lunak

290
00:11:53,290 --> 00:11:55,120
dan itu akan menjadi
sistem yang besar.

291
00:11:55,120 --> 00:11:57,010
Mereka akan memiliki banyak bug.

292
00:11:57,010 --> 00:11:58,490
Dan Anda memperbaikinya.

293
00:11:58,490 --> 00:11:59,950
Kalian mengganti sedikit
model ancaman kalian.

294
00:11:59,950 --> 00:12:02,900
Dan kalian mengiterasi hal tersebut dan
mencoba merancang sebuah sistem baru,

295
00:12:02,900 --> 00:12:06,720
dan semoga membuat segalanya
menjadi lebih baik.

296
00:12:06,720 --> 00:12:10,640
Jadi satu kemungkinan interpretasi 
dari kelas ini-- baik,

297
00:12:10,640 --> 00:12:14,360
satu bahayanya-- adalah bahwa Anda 
berpikir, wah, semuanya

298
00:12:14,360 --> 00:12:15,070
rusak.

299
00:12:15,070 --> 00:12:15,780
Tidak ada yang berhasil.

300
00:12:15,780 --> 00:12:18,390
Kita menyerah saja
dan berhenti menggunakan komputer.

301
00:12:18,390 --> 00:12:21,460
Dan ini adalah salah satu
kemungkinan interpretasi.

302
00:12:21,460 --> 00:12:23,752
Namun hal ini mungkin tidak
cukup benar.

303
00:12:23,752 --> 00:12:25,210
Alasan hal-hal
tersebut akan muncul

304
00:12:25,210 --> 00:12:26,585
atau Anda akan
berpikir seperti ini

305
00:12:26,585 --> 00:12:28,060
adalah karena,
sepanjang kelas ini,

306
00:12:28,060 --> 00:12:29,850
kita akan melihat semua
sistem yang berbeda ini,

307
00:12:29,850 --> 00:12:31,270
dan nampaknya kita akan
menguji sistem-sistem ini hingga batasnya.

308
00:12:31,270 --> 00:12:33,100
Mari kita lihat, OK,
baiklah, bagaimana jika kita melakukan ini?

309
00:12:33,100 --> 00:12:33,690
Apakah ini akan hancur?

310
00:12:33,690 --> 00:12:34,320
Bagaimana jika kita melakukan itu?

311
00:12:34,320 --> 00:12:35,519
Apakah akan hancur juga?

312
00:12:35,519 --> 00:12:37,060
Dan pastinya,
semua sistem akan

313
00:12:37,060 --> 00:12:38,643
memiliki sebuah
batas kekuatan.

314
00:12:38,643 --> 00:12:39,860
Dan akan kita pecahkan, oh hei.

315
00:12:39,860 --> 00:12:42,420
Sistem ini, dapat kita rusak
jika kita melakukan dengan cara ini.

316
00:12:42,420 --> 00:12:46,260
Dan sistem ini tidak bekerja
dalam beberapa asumsi ini.

317
00:12:46,260 --> 00:12:48,195
Dan tidak bisa dihindari
bahwa setiap sistem

318
00:12:48,195 --> 00:12:49,320
akan memiliki batas kekuatan.

319
00:12:49,320 --> 00:12:51,380
Namun bukan berarti
setiap sistem tidak berguna.

320
00:12:51,380 --> 00:12:52,920
Itu hanya berarti bahwa
kalian harus tahu kapan

321
00:12:52,920 --> 00:12:54,980
kita menggunakan setiap rancangan sistem.

322
00:12:54,980 --> 00:12:57,360
Dan ini nampak berguna
untuk melakukan pengujian

323
00:12:57,360 --> 00:12:59,130
untuk mencari
kelemahannya sehingga Anda

324
00:12:59,130 --> 00:13:03,530
tahu kapan ide-ide tertentu dapat dipakai,
kapan ide tertentu tidak 

325
00:13:03,530 --> 00:13:04,940
tidak dapat dipakai.

326
00:13:04,940 --> 00:13:09,190
Dalam kenyataannya, ini 
batasan yang agak membingungkan, benar?

327
00:13:09,190 --> 00:13:11,660
Semakin aman sistem yang
Anda bangun, semakin kecil kemungkinan

328
00:13:11,660 --> 00:13:14,910
bagi Anda untuk muncul dalam cerita
memalukan di halaman depan New

329
00:13:14,910 --> 00:13:17,000
York Times yang mengatakan,
perusahaan baru Anda

330
00:13:17,000 --> 00:13:21,460
membocorkan nomor keamanan
dari satu juta orang.

331
00:13:21,460 --> 00:13:26,770
Dan kemudian Anda bayar lebih sedikit
untuk pulih dari bencana tersebut.

332
00:13:26,770 --> 00:13:29,650
Dan saya kira satu catatan yang
benar-benar positif tentang keamanan

333
00:13:29,650 --> 00:13:33,230
adalah bahwa, dalam banyak hal, keamanan memungkinkan
Anda untuk melakukan hal-hal keren yang Anda

334
00:13:33,230 --> 00:13:36,450
tidak bisa lakukan sebelumnya, karena
keamanan, terutama

335
00:13:36,450 --> 00:13:40,170
mekanisme, yang memungkinkan
kita untuk berlindung

336
00:13:40,170 --> 00:13:43,140
dari beberapa jenis serangan,
cukup kuat.

337
00:13:43,140 --> 00:13:46,512
Sebagai contoh, peramban (web browser) sebelumnya
cukup membosankan dalam hal

338
00:13:46,512 --> 00:13:47,720
apa yang bisa Anda lakukan dengannya.

339
00:13:47,720 --> 00:13:49,270
Anda hanya bisa melihat
halaman web, mungkin

340
00:13:49,270 --> 00:13:50,930
menjalankan beberapa kode JavaScript di dalamnya.

341
00:13:50,930 --> 00:13:52,710
Namun sekarang ada semua
mekanisme keren ini

342
00:13:52,710 --> 00:13:54,420
yang akan kita pelajari
dalam beberapa minggu

343
00:13:54,420 --> 00:13:57,810
yang memungkinkan Anda untuk menjalankan
kode asli x86 (native code) dalam peramban

344
00:13:57,810 --> 00:13:59,530
web dan memastikan bahwa
penjelajah web tersebut tidak melakukan

345
00:13:59,530 --> 00:14:01,260
hal-hal lucu terhadap komputer Anda.

346
00:14:01,260 --> 00:14:04,154
Dan peramban bisa mengirimkan-- dan
ada sebuah teknik atau sistem

347
00:14:04,154 --> 00:14:06,070
yang disebut dengan Native Client
dari Google yang sebenarnya

348
00:14:06,070 --> 00:14:08,200
memungkinkan kita untuk melakukan hal ini dengan aman.

349
00:14:08,200 --> 00:14:11,127
Dan sebelumnya, untuk menjalankan beberapa 
permainan di komputer Anda,

350
00:14:11,127 --> 00:14:13,710
Anda harus mengunduh dan menginstalnya,
mengklik banyak kotak

351
00:14:13,710 --> 00:14:15,671
dialog, mengatakan ya, saya mengizinkan ini.

352
00:14:15,671 --> 00:14:17,420
Namun sekarang, Anda bisa
menjalankannya dalam sebuah peramban,

353
00:14:17,420 --> 00:14:18,600
tanpa perlu mengklik apapun.

354
00:14:18,600 --> 00:14:19,510
Permainan tersebut langsung jalan.

355
00:14:19,510 --> 00:14:22,200
Dan alasan mengapa hal itu
sangat mudah dan kuat

356
00:14:22,200 --> 00:14:25,990
adalah karena mekanisme keamanan kita
dapat memasukkan program ini ke dalam kotak pasir (sandbox)

357
00:14:25,990 --> 00:14:29,590
dan tidak perlu berasumsi apapun
tentang pengguna yang memilih

358
00:14:29,590 --> 00:14:31,730
permainan yang benar dan tidak memilih
permainan berbahaya untuk dimainkan

359
00:14:31,730 --> 00:14:34,460
pada komputer mereka, atau memilih
beberapa program lain untuk dijalankan.

360
00:14:34,460 --> 00:14:36,270
Jadi dalam banyak hal, mekanisme
keamanan yang baik

361
00:14:36,270 --> 00:14:40,610
akan memungkinkan pembangunan sistem
baru yang keren yang tidak

362
00:14:40,610 --> 00:14:43,551
mungkin dibuat sebelumnya.

363
00:14:43,551 --> 00:14:44,050
Baiklah.

364
00:14:44,050 --> 00:14:45,420
Masuk akal?

365
00:14:45,420 --> 00:14:50,485
Ada pertanyaan tentang cerita ini?

366
00:14:50,485 --> 00:14:51,890
Baiklah.

367
00:14:51,890 --> 00:14:54,150
Jadi saya kira selama
sisa kuliah ini,

368
00:14:54,150 --> 00:14:58,320
saya ingin melihat sekumpulan
contoh berbeda tentang bagaimana

369
00:14:58,320 --> 00:15:00,000
keamanan menjadi tidak semestinya.

370
00:15:00,000 --> 00:15:02,680
Jadi, sejauh ini, kita telah melihat
bagaimana Anda dapat memikirkannya.

371
00:15:02,680 --> 00:15:05,790
Namun mau tidak mau, ada
baiknya melihat contoh

372
00:15:05,790 --> 00:15:10,230
tentang apa yang tidak boleh dilakukan agar Anda 
bisa memiliki pola pikir yang lebih baik ketika

373
00:15:10,230 --> 00:15:12,470
Anda mendekati
masalah keamanan.

374
00:15:12,470 --> 00:15:16,586
Dan dalam masalah tentang
bobolnya sistem keamanan,

375
00:15:16,586 --> 00:15:18,942
kurang lebih setiap satu dari
tiga hal ini menjadi tidak semestinya.

376
00:15:18,942 --> 00:15:20,650
Dalam praktiknya, orang-orang
salah dalam mengambil kebijakan,

377
00:15:20,650 --> 00:15:22,066
orang-orang salah
dalam menentukan model ancaman,

378
00:15:22,066 --> 00:15:23,580
dan orang-orang salah
dalam memahami mekanisme.

379
00:15:23,580 --> 00:15:27,280
Dan mari, saya kira, mulai
dari beberapa kebijakan dan contoh

380
00:15:27,280 --> 00:15:31,420
tentang bagaimana Anda dapat 
mengacaukan kebijakan sistem.

381
00:15:31,420 --> 00:15:35,220
Mungkin contoh yang paling bersih
atau paling sederhana dari hal ini

382
00:15:35,220 --> 00:15:38,350
adalah pertanyaan pemulihan akun.

383
00:15:41,810 --> 00:15:46,282
Jadi biasanya, saat Anda
masuk ke dalam sebuah situs web,

384
00:15:46,282 --> 00:15:47,240
Anda akan memasukkan sebuah password.

385
00:15:47,240 --> 00:15:49,640
Namun apa yang terjadi jika
Anda kehilangan password Anda?

386
00:15:49,640 --> 00:15:52,570
Beberapa situs akan mengirimkan
Anda email jika Anda

387
00:15:52,570 --> 00:15:55,190
kehilangan password Anda dengan sebuah 
tautan untuk mengatur ulang password Anda.

388
00:15:55,190 --> 00:15:57,481
Jadi cukup mudah, jika Anda
memiliki alamat email yang lain.

389
00:15:57,481 --> 00:15:59,400
Tapi bagaimana jika masalahnya datang dari
penyedia alamat email Anda?

390
00:15:59,400 --> 00:16:03,700
Jadi setidaknya, beberapa 
tahun yang lalu, Yahoo

391
00:16:03,700 --> 00:16:06,660
memiliki layanan email, webmail, untuk
siapapun di internet.

392
00:16:06,660 --> 00:16:08,572
Dan ketika Anda lupa
password Yahoo Anda,

393
00:16:08,572 --> 00:16:10,030
mereka tidak benar-benar bisa
mengirimkan Anda email

394
00:16:10,030 --> 00:16:11,610
karena Anda tidak bisa mengaksesnya.

395
00:16:11,610 --> 00:16:13,420
Jadi sebagai gantinya, mereka
meminta Anda untuk mendaftarkan

396
00:16:13,420 --> 00:16:16,317
beberapa pertanyaan dengan
harapan bahwa hanya Anda saja yang mengetahuinya.

397
00:16:16,317 --> 00:16:18,650
Dan jika Anda lupa password Anda,
Anda dapat mengklik sebuah tautan

398
00:16:18,650 --> 00:16:21,130
dan berkata, baiklah, ini adalah
jawaban untuk pertanyaan-pertanyaan saya.

399
00:16:21,130 --> 00:16:23,480
Biarkan saya mendapatkan password saya kembali.

400
00:16:23,480 --> 00:16:26,360
Dan ternyata yang
menjadi masalah adalah-- baiklah,

401
00:16:26,360 --> 00:16:30,430
beberapa orang tidak menyadari 
bahwa hal ini mengubah kebijakan Anda,

402
00:16:30,430 --> 00:16:32,800
karena sebelumnya, 
kebijakan dari sebuah sistem

403
00:16:32,800 --> 00:16:35,280
adalah orang-orang yang dapat masuk
adalah orang-orang yang

404
00:16:35,280 --> 00:16:36,931
mengetahui passwordnya.

405
00:16:36,931 --> 00:16:38,930
Dan saat Anda mengajukan
pertanyaan-pertanyaan pemulihan ini,

406
00:16:38,930 --> 00:16:40,596
kebijakannya menjadi,
baiklah, kalian dapat masuk

407
00:16:40,596 --> 00:16:44,380
jika Anda mengetahui password
atau pertanyaan keamanannya.

408
00:16:44,380 --> 00:16:47,001
Jadi hal itu melemahkan
sistem kemamanan Anda.

409
00:16:47,001 --> 00:16:49,250
Dan banyak orang telah
mengambil keuntungan dari hal ini.

410
00:16:49,250 --> 00:16:53,410
Salah satu contoh yang terkenal
adalah, saya pikir beberapa tahun lalu,

411
00:16:53,410 --> 00:16:55,820
Sarah Pailin pernah memiliki
akun email di Yahoo.

412
00:16:55,820 --> 00:16:59,390
dan pertanyaan-pertanyaan keamanan dia
adalah pertanyaan tentang hal-hal semacam, yah,

413
00:16:59,390 --> 00:17:00,660
di mana Anda bersekolah?

414
00:17:00,660 --> 00:17:03,406
Siapa nama teman Anda?

415
00:17:03,406 --> 00:17:04,280
Kapan hari tanggal lahirmu?

416
00:17:04,280 --> 00:17:04,960
Dan lain-lain.

417
00:17:04,960 --> 00:17:07,430
Hal-hal tersebut merupakan hal-hal yang
telah tertulis di halaman Wikipedia tentangnya.

418
00:17:07,430 --> 00:17:09,690
Dan sebagai konsekuensinya,
seseorang dapat dengan cukup mudah,

419
00:17:09,690 --> 00:17:12,839
dan seseorang telah melakukannya, tentunya,
masuk ke dalam akun email Yahoo dia

420
00:17:12,839 --> 00:17:15,319
hanya dengan melihat di Wikipedia tentang
di mana dia bersekolah saat SMA

421
00:17:15,319 --> 00:17:17,379
dan kapan hari ulang tahunnya.

422
00:17:17,379 --> 00:17:18,920
Maka Anda harus
berpikir dengan hati-hati

423
00:17:18,920 --> 00:17:21,890
tentang implikasi
dari bermacam kebijakan

424
00:17:21,890 --> 00:17:24,819
keamanan yang Anda buat di sini.

425
00:17:24,819 --> 00:17:29,220
Mungkin, contoh yang lebih rumit, dan
mungkin, lebih menarik,

426
00:17:29,220 --> 00:17:32,720
adalah apa yang terjadi ketika Anda
memiliki banyak sistem yang mulai

427
00:17:32,720 --> 00:17:34,750
berinteraksi satu sama lain.

428
00:17:34,750 --> 00:17:39,340
Jadi ada cerita bagus
tentang seorang pria bernama Mat Honan.

429
00:17:39,340 --> 00:17:42,660
Mungkin Anda membaca
cerita ini satu atau dua tahun lalu.

430
00:17:42,660 --> 00:17:45,900
Dia adalah seorang editor di
majalah wired.com.

431
00:17:45,900 --> 00:17:48,150
Dan memiliki sedikit masalah.

432
00:17:48,150 --> 00:17:50,550
Sederhananya, seseorang berhasil
masuk ke akun Gmail miliknya

433
00:17:50,550 --> 00:17:52,340
dan melakukan banyak hal buruk.

434
00:17:52,340 --> 00:17:53,590
Namun bagaimana mereka melakukannya, betul?

435
00:17:53,590 --> 00:17:54,870
Maka hal ini cukup menarik.

436
00:17:54,870 --> 00:17:57,640
Jadi semua pihak dalam
cerita ini terlihat

437
00:17:57,640 --> 00:17:58,890
melakukan hal-hal yang masuk akal.

438
00:17:58,890 --> 00:18:01,181
Namun akan kita lihat bagaimana mereka melakukan
sesuatu yang merugikan.

439
00:18:01,181 --> 00:18:02,530
Jadi kita punya Gmail.

440
00:18:02,530 --> 00:18:06,580
Dan Gmail memungkinkan Anda untuk
mengatur ulang password Anda

441
00:18:06,580 --> 00:18:09,700
jika Anda lupa, seperti pada
sistem-sistem lainnya.

442
00:18:09,700 --> 00:18:13,670
Dan cara Anda mengatur ulang
password di Gmail

443
00:18:13,670 --> 00:18:16,090
adalah Anda mengirimkan
permohonan pengaturan ulang.

444
00:18:16,090 --> 00:18:19,030
Dan apa yang mereka katakan
adalah, yah, Anda tidak akan

445
00:18:19,030 --> 00:18:21,420
menjawab pertanyaan
pemulihan ini, setidaknya

446
00:18:21,420 --> 00:18:22,306
tidak untuk orang ini.

447
00:18:22,306 --> 00:18:24,930
Apa yang mereka lakukan adalah mengirimkan
sebuah tautan pemulihan ke alamat email

448
00:18:24,930 --> 00:18:27,130
cadangan, atau beberapa alamat
email lain yang Anda miliki.

449
00:18:27,130 --> 00:18:29,588
Dan untuk membantu, mereka
mencetak alamat email tersebut untuk Anda.

450
00:18:29,588 --> 00:18:31,139
Jadi untuk akun milik orang ini,
seseorang

451
00:18:31,139 --> 00:18:32,930
meminta Gmail untuk mengatur ulang
password Gmail tersebut.

452
00:18:32,930 --> 00:18:33,830
Dan mereka bilang, yah, baiklah.

453
00:18:33,830 --> 00:18:34,330
Tentu.

454
00:18:34,330 --> 00:18:37,080
Kita baru saja mengirimkan tautan
pemulihan ke email ini,

455
00:18:37,080 --> 00:18:42,089
foo@me.com, yang merupakan
layanan email dari Apple.

456
00:18:42,089 --> 00:18:44,505
OK, tapi orang jahat tersebut tidak
memiliki akses ke me.com, juga.

457
00:18:44,505 --> 00:18:46,860
Namun mereka ingin mendapatkan
tautan untuk mengatur ulang password ini

458
00:18:46,860 --> 00:18:48,790
untuk mendapatkan akses ke Gmail.

459
00:18:48,790 --> 00:18:50,860
Baiklah, bagaimana hal-hal tersebut
bekerja adalah bahwa,

460
00:18:50,860 --> 00:18:55,980
dalam kasus Apple,
situs me.com ini

461
00:18:55,980 --> 00:19:00,830
memungkinkan Anda untuk mengatur
ulang password Anda jika Anda mengetahui

462
00:19:00,830 --> 00:19:03,580
alamat penagihan Anda dan empat
dijit terakhir dari nomor

463
00:19:03,580 --> 00:19:05,112
kartu kredit Anda.

464
00:19:05,112 --> 00:19:07,300
Jadi masih belum jelas bagaimana
Anda akan mendapatkan

465
00:19:07,300 --> 00:19:10,591
alamat rumah-- yah, milik orang ini,
mungkin Anda bisa mencarinya

466
00:19:10,591 --> 00:19:11,090
di suatu tempat.

467
00:19:11,090 --> 00:19:12,981
Pria ini adalah orang
yang terkenal saat itu.

468
00:19:12,981 --> 00:19:15,480
Namun dari mana Anda mendapatkan
empat angka terakhir dari

469
00:19:15,480 --> 00:19:16,640
kartu kreditnya?

470
00:19:16,640 --> 00:19:21,177
Yah, tidak jelas, tapi
mari kita lanjutkan.

471
00:19:21,177 --> 00:19:23,510
Jadi Anda perlu mengirimkan seluruh hal
ini ke me.com untuk mendapatkan akses

472
00:19:23,510 --> 00:19:25,652
ke akun emailnya di sana.

473
00:19:25,652 --> 00:19:28,110
Yah, ternyata pria ini
memiliki akun di Amazon, yang merupakan

474
00:19:28,110 --> 00:19:31,250
pihak lain dalam cerita ini.

475
00:19:31,250 --> 00:19:34,460
Amazon benar-benar ingin
Anda membeli sesuatu.

476
00:19:34,460 --> 00:19:38,030
Dan sebagai konsekuensinya, mereka
sebenarnya memiliki sistem pengelolaan akun

477
00:19:38,030 --> 00:19:39,770
yang cukup rumit.

478
00:19:39,770 --> 00:19:42,950
Dan khususnya, karena mereka
sangat ingin Anda membeli barang,

479
00:19:42,950 --> 00:19:44,490
mereka tidak meminta
Anda untuk mendaftar

480
00:19:44,490 --> 00:19:47,670
untuk membeli beberapa barang
dengan kartu kredit.

481
00:19:47,670 --> 00:19:50,710
Jadi saya dapat membuka Amazon,
atau paling tidak saat itu,

482
00:19:50,710 --> 00:19:53,400
saya bisa mengunjungi Amazon
dan berkata, yah, saya penggunanya.

483
00:19:53,400 --> 00:19:57,490
Dan saya ingin membeli
satu bungkus sikat gigi ini.

484
00:19:57,490 --> 00:20:00,140
Dan jika saya ingin menggunakan
nomor kartu kredit yang disimpan

485
00:20:00,140 --> 00:20:02,640
di akun pria itu, saya seharusnya
tidak dapat melakukan ini.

486
00:20:02,640 --> 00:20:05,740
Namun jika saya mendaftarkan
kartu kredit baru, apa yang Amazon

487
00:20:05,740 --> 00:20:08,280
akan lakukan adalah, mereka sebenarnya
dapat menambah sebuah kartu kredit

488
00:20:08,280 --> 00:20:13,500
baru ke akun milik seseorang.

489
00:20:13,500 --> 00:20:15,500
Jadi sepertinya tidak 
terlalu buruk, bukan?

490
00:20:15,500 --> 00:20:17,060
Pada dasarnya saya
memesan sikat gigi

491
00:20:17,060 --> 00:20:18,839
melalui salah satu akun
Amazon milik Anda.

492
00:20:18,839 --> 00:20:20,380
Namun bagaimana pun juga
itu bukan kartu kredit Anda.

493
00:20:20,380 --> 00:20:22,380
Itu hanya nomor kartu
kredit saya yang sedang digunakan.

494
00:20:22,380 --> 00:20:24,220
Jadi masih belum jelas bagaimana
hal ini menjadi tidak semestinya.

495
00:20:24,220 --> 00:20:26,630
Namun Amazon memiliki
antarmuka yang lain.

496
00:20:26,630 --> 00:20:28,430
Semua hal ini adalah
sistem yang rumit.

497
00:20:28,430 --> 00:20:31,700
Dan Amazon memiliki sebuah antarmuka
untuk mengatur ulang password.

498
00:20:31,700 --> 00:20:34,550
Dan untuk mengatur ulang
password di Amazon,

499
00:20:34,550 --> 00:20:38,230
apa yang harus Anda siapkan hanyalah
nomor kartu kredit dari

500
00:20:38,230 --> 00:20:39,560
seorang pengguna.

501
00:20:39,560 --> 00:20:42,424
Jadi saya dapat memesan barang dan
menambah sebuah nomor kartu kredit

502
00:20:42,424 --> 00:20:43,090
ke akun Anda.

503
00:20:43,090 --> 00:20:45,298
Dan kemudian saya dapat mengatakan, hei, saya
ingin mengatur ulang password saya.

504
00:20:45,298 --> 00:20:46,920
Ini adalah salah satu 
nomer kartu kredit saya.

505
00:20:46,920 --> 00:20:48,900
Dan hal ini, faktanya, berhasil.

506
00:20:48,900 --> 00:20:53,590
Jadi ini adalah titik di mana si orang jahat
mendapatkan akun Amazon milik

507
00:20:53,590 --> 00:20:54,920
orang ini, Mat.

508
00:20:54,920 --> 00:20:55,420
Namun baiklah.

509
00:20:55,420 --> 00:20:57,260
Bagaimana Anda memancing keluar
nomor kartu kredit

510
00:20:57,260 --> 00:20:59,350
untuk mengatur ulang situs Apple?

511
00:20:59,350 --> 00:21:01,010
Yah, Amazon dulunya
sangat berhati-hati.

512
00:21:01,010 --> 00:21:03,010
Bahkan jika Anda membobol
akun Amazon seseorang,

513
00:21:03,010 --> 00:21:05,620
Amazon tidak akan mencetak nomor
kartu kredit yang tersimpan

514
00:21:05,620 --> 00:21:07,700
milik orang tersebut.

515
00:21:07,700 --> 00:21:09,284
Namun Amazon akan menunjukkan
empat angka terakhirnya.

516
00:21:09,284 --> 00:21:11,616
Sehingga Anda tahu kartu 
kredit mana yang dimaksud.

517
00:21:11,616 --> 00:21:14,220
Jadi anda dapat melihat daftar semua kartu  
kredit, selain kartu kredit yang 

518
00:21:14,220 --> 00:21:14,930
sudah Anda tambahkan.

519
00:21:14,930 --> 00:21:16,770
Kemudian Anda dapat mengunjungi dan
masuk ke me.com.

520
00:21:16,770 --> 00:21:19,620
Anda dapat mengklik tautan
ini dan mendapatkan akses

521
00:21:19,620 --> 00:21:21,281
ke akun Gmail pria itu.

522
00:21:21,281 --> 00:21:22,530
Semua hal ini sangatlah rumit.

523
00:21:22,530 --> 00:21:24,380
Dan jika terisolasi,
setiap sistem tampak

524
00:21:24,380 --> 00:21:26,880
melakukan hal-hal
yang masuk akal.

525
00:21:26,880 --> 00:21:28,590
Namun sebenarnya
cukup sulit untuk memikirkan

526
00:21:28,590 --> 00:21:31,560
tentang segala kerentanan
dan kelemahan ini

527
00:21:31,560 --> 00:21:34,480
kecuali Anda memiliki gambaran
keseluruhan ini dijelaskan kepada Anda

528
00:21:34,480 --> 00:21:37,380
dan Anda harus mengumpulkan
potongan-potongan ini menjadi satu.

529
00:21:37,380 --> 00:21:41,310
Jadi hal ini sebenarnya
cukup rumit.

530
00:21:41,310 --> 00:21:45,012
Dan sayangnya, yah,
sepertinya untuk masing-masing

531
00:21:45,012 --> 00:21:47,470
kategori ini, jawaban untuk
bagaimana menghindari hal ini

532
00:21:47,470 --> 00:21:50,630
adalah seringkali dengan berpikir keras
dan berhati-hati.

533
00:21:50,630 --> 00:21:54,330
Saya rasa rencana umumnya
adalah, dengan bersikap konservatif dalam hal

534
00:21:54,330 --> 00:21:57,960
mengatur kebijakan Anda
akan seperti apa,

535
00:21:57,960 --> 00:22:01,540
untuk mungkin tidak bergantung pada hal-hal
yang mungkin diungkap situs lain.

536
00:22:01,540 --> 00:22:05,645
Jadi yah, saya tidak yakin jika ada
nasihat yang sangat bagus yang dapat

537
00:22:05,645 --> 00:22:06,942
mencegah masalah ini.

538
00:22:06,942 --> 00:22:07,650
Namun sekarang Anda tahu.

539
00:22:07,650 --> 00:22:11,180
Dan sekarang Anda akan membuat
kesalahan lain.

540
00:22:11,180 --> 00:22:13,970
Ada sangat banyak
contoh kebijakan lain

541
00:22:13,970 --> 00:22:18,577
yang salah dan dapat
membahayakan suatu sistem.

542
00:22:18,577 --> 00:22:19,660
Hal itu cukup menarik.

543
00:22:19,660 --> 00:22:22,550
Namun mari kita lihat bagaimana orang-orang
mungkin mengacaukan model-model ancaman.

544
00:22:22,550 --> 00:22:28,020
Jadi saya akan matikan
kotak biru ini.

545
00:22:28,020 --> 00:22:28,520
OK.

546
00:22:28,520 --> 00:22:36,060
Jadi apa contoh model ancaman
yang salah?

547
00:22:36,060 --> 00:22:42,410
Baik, mungkin satu contoh besar yang ada
dalam praktiknya adalah faktor manusia.

548
00:22:42,410 --> 00:22:45,970
Jadi kita sering membuat
asumsi tentang apa

549
00:22:45,970 --> 00:22:49,040
yang akan orang lakukan dalam
sebuah sistem, seperti mereka akan

550
00:22:49,040 --> 00:22:51,150
memilih password
yang bagus dan kuat,

551
00:22:51,150 --> 00:22:53,920
atau mereka tidak akan mengklik
situs-situs sembarangan

552
00:22:53,920 --> 00:22:56,800
yang mereka terima melalui email
dan memasukkan password mereka di sana.

553
00:22:56,800 --> 00:22:59,594
Jadi itu tadi adalah-- yah,
seperti yang mungkin Anda curiga,

554
00:22:59,594 --> 00:23:01,260
dan dalam praktiknya,
memang terjadi demikian,

555
00:23:01,260 --> 00:23:03,800
hal ini bukanlah asumsi
yang baik dalam banyak kasus.

556
00:23:03,800 --> 00:23:06,020
Dan orang-orang memilih password yang buruk.

557
00:23:06,020 --> 00:23:08,510
Dan orang-orang akan mengklik
sembarang tautan.

558
00:23:08,510 --> 00:23:10,350
Dan orang-orang akan
memasukkan password mereka ke

559
00:23:10,350 --> 00:23:13,510
dalam situs yang
tidak benar.

560
00:23:13,510 --> 00:23:16,990
Dan mereka tidak akan
memperhatikan hal tersebut.

561
00:23:16,990 --> 00:23:19,960
Jadi Anda mungkin tidak menginginkan
model ancaman yang

562
00:23:19,960 --> 00:23:21,600
berasumsi kuat
tentang apa yang

563
00:23:21,600 --> 00:23:23,433
manusia akan lakukan karena
pastinya, sesuatu

564
00:23:23,433 --> 00:23:25,610
akan menjadi tidak semestinya.

565
00:23:25,610 --> 00:23:26,720
Masuk akal?

566
00:23:26,720 --> 00:23:29,220
Ada pertanyaan?

567
00:23:29,220 --> 00:23:29,850
Baiklah.

568
00:23:29,850 --> 00:23:32,690
Hal bagus lainnya untuk
diperhatikan dalam model ancaman

569
00:23:32,690 --> 00:23:35,860
adalah bahwa mereka kadang-kadang
berubah seiring berjalannya waktu.

570
00:23:35,860 --> 00:23:38,160
Atau apakah suatu hal merupakan
sebuah asumsi yang bagus atau tidak

571
00:23:38,160 --> 00:23:40,160
berubah seiring berjalannya waktu.

572
00:23:40,160 --> 00:23:45,420
Satu contoh dari hal ini sebenarnya
di MIT pada pertengahan 90-an-- pertengahan

573
00:23:45,420 --> 00:23:48,080
80-an, sebenarnya--
Project Athena mengembangkan

574
00:23:48,080 --> 00:23:49,250
sistem ini yang bernama Kerberos.

575
00:23:49,250 --> 00:23:52,830
Dan kita akan membaca tentang sistem itu
dalam beberapa minggu ke depan di kelas ini.

576
00:23:52,830 --> 00:23:55,640
Dan pada waktu itu, mereka semacam
mencari tahu, yah, Kerberos

577
00:23:55,640 --> 00:23:57,181
akan didasarkan
pada kriptografi.

578
00:23:57,181 --> 00:23:59,331
Jadi kita perlu memilih
beberapa ukuran kunci

579
00:23:59,331 --> 00:24:00,830
untuk memastikan mereka
tidak akan

580
00:24:00,830 --> 00:24:02,570
ditebak oleh sembarangan orang.

581
00:24:02,570 --> 00:24:03,320
Dan mereka berkata, OK.

582
00:24:03,320 --> 00:24:06,120
Yah Anda tahu, kunci
56-bit, pada saat itu,

583
00:24:06,120 --> 00:24:09,960
untuk metode enkripsi ini yang disebut DES,
tampak seperti ukuran yang dapat diterima.

584
00:24:09,960 --> 00:24:13,700
Mungkin tidak fantastis, tapi tentu saja
tidak sepenuhnya tidak masuk akal.

585
00:24:13,700 --> 00:24:14,997
Dan hal ini terjadi di pertengahan tahun 80-an.

586
00:24:14,997 --> 00:24:17,580
Namun kemudian Anda tahu, sistem ini
menjadi populer dan banyak digunakan.

587
00:24:17,580 --> 00:24:19,400
MIT masih menggunakannya.

588
00:24:19,400 --> 00:24:22,400
Dan mereka tidak pernah benar-benar
meninjau kembali asumsi ini

589
00:24:22,400 --> 00:24:23,900
dengan serius.

590
00:24:23,900 --> 00:24:27,244
Dan kemudian, beberapa tahun yang lalu,
sekelompok mahasiswa 6.858

591
00:24:27,244 --> 00:24:29,910
menemukan bahwa sebenarnya, yah,
Anda dapat memecahkan ini, kan?

592
00:24:29,910 --> 00:24:34,480
Kini cukup mudah untuk
menghitung seluruh 256 kunci.

593
00:24:34,480 --> 00:24:36,570
Komputer sangat cepat,
Anda dapat melakukannya.

594
00:24:36,570 --> 00:24:38,780
Dan hasilnya,
mereka dapat melakukannya,

595
00:24:38,780 --> 00:24:42,619
dengan bantuan beberapa
perangkat keras dari layanan web

596
00:24:42,619 --> 00:24:45,160
tertentu-- kita akan memiliki beberapa
tautan catatan kuliah-- mereka

597
00:24:45,160 --> 00:24:50,170
pada dasarnya, bisa mendapatkan kunci
akun Kerberos siapa pun dalam waktu kira-kira

598
00:24:50,170 --> 00:24:51,100
sehari.

599
00:24:51,100 --> 00:24:55,030
Dan asumsi ini
bagus di pertengahan 1980-an.

600
00:24:55,030 --> 00:24:57,210
Bukan lagi asumsi yang bagus
untuk hari ini.

601
00:24:57,210 --> 00:24:59,850
Jadi Anda benar-benar
harus memastikan bahwa asumsi Anda

602
00:24:59,850 --> 00:25:02,220
mengikuti perkembangan zaman.

603
00:25:02,220 --> 00:25:06,140
Mungkin contoh yang lebih tepat waktu
adalah, jika musuh Anda--

604
00:25:06,140 --> 00:25:08,980
atau jika Anda khawatir
dengan serangan pemerintah,

605
00:25:08,980 --> 00:25:12,371
Anda dapat menyadari bahwa Anda
tidak seharusnya mempercayai perangkat keras bahkan

606
00:25:12,371 --> 00:25:13,120
hari ini, benar?

607
00:25:13,120 --> 00:25:14,870
Ada semua
pengungkapan tentang apa

608
00:25:14,870 --> 00:25:16,860
yang NSA dapat lakukan.

609
00:25:16,860 --> 00:25:18,590
Dan mereka memiliki
back doors dari perangkat keras

610
00:25:18,590 --> 00:25:20,922
yang dapat mereka masukan
ke dalam komputer.

611
00:25:20,922 --> 00:25:23,444
Dan mungkin sampai beberapa
tahun yang lalu, yah, siapa yang tahu?

612
00:25:23,444 --> 00:25:25,110
Saya kira kita tidak
mengetahui hal-hal seperti ini.

613
00:25:25,110 --> 00:25:27,360
Jadi saat itu mungkin ini adalah
asumsi yang masuk akal

614
00:25:27,360 --> 00:25:29,270
untuk membuat asumsi bahwa
laptop Anda tidak akan

615
00:25:29,270 --> 00:25:31,962
dirusak secara fisik,
dengan perangkat keras itu sendiri.

616
00:25:31,962 --> 00:25:32,670
Namun sekarang Anda tahu.

617
00:25:32,670 --> 00:25:34,670
Sebenarnya, jika Anda khawatir
tentang pemerintah

618
00:25:34,670 --> 00:25:37,190
mengejar Anda, Anda mungkin
akan memiliki masalah yang jauh lebih sulit

619
00:25:37,190 --> 00:25:39,009
untuk ditangani karena
laptop Anda mungkin

620
00:25:39,009 --> 00:25:40,550
dirusak
secara fisik, apapun

621
00:25:40,550 --> 00:25:42,621
yang Anda pasang di dalamnya.

622
00:25:42,621 --> 00:25:44,870
Jadi kita benar-benar harus
berhati-hati dengan model ancaman Anda

623
00:25:44,870 --> 00:25:46,820
dan benar-benar
menyeimbangkannya dengan siapa

624
00:25:46,820 --> 00:25:48,236
yang menurut Anda akan mendapatkan Anda.

625
00:25:48,236 --> 00:25:50,860
Saya pikir itu akan menjadi sangat
proposisi mahal jika Anda

626
00:25:50,860 --> 00:25:53,302
akan mencoba melindungi
diri Anda dari NSA, sungguh.

627
00:25:53,302 --> 00:25:55,510
Di sisi lain, jika Anda
hanya melindungi dirimu sendiri

628
00:25:55,510 --> 00:25:57,772
dari siswa acak
lainnya yang,

629
00:25:57,772 --> 00:26:00,230
saya tidak tahu, mengintip
direktori home Athena Anda

630
00:26:00,230 --> 00:26:01,938
atau yang lainnya, mungkin Anda 
tidak perlu khawatir

631
00:26:01,938 --> 00:26:03,210
tentang hal ini.

632
00:26:03,210 --> 00:26:06,320
Jadi hal ini benar-benar sebuah permainan menyeimbangkan
dan memilih model ancaman yang

633
00:26:06,320 --> 00:26:08,610
benar.

634
00:26:08,610 --> 00:26:15,370
Contoh lain dari model ancaman
yang buruk muncul dalam cara

635
00:26:15,370 --> 00:26:18,307
situs-situs web yang aman saat ini
memeriksa sertifikat situs web

636
00:26:18,307 --> 00:26:19,390
yang terhubung dengan Anda.

637
00:26:19,390 --> 00:26:23,350
Jadi di dalam protokol SSL atau TLS,
saat Anda terhubung ke situs web

638
00:26:23,350 --> 00:26:25,860
dan dia berbicara HTTPS-- kita akan
berbicara lebih lanjut tentang hal ini

639
00:26:25,860 --> 00:26:28,710
di kuliah nanti--
tetapi apa yang terjadi

640
00:26:28,710 --> 00:26:30,955
adalah ketika situs yang terhubung
dengan Anda memberikan Anda

641
00:26:30,955 --> 00:26:34,800
sebuah sertifikat yang ditandatangani oleh salah 
satu otoritas sertifikat (certificate authorities)

642
00:26:34,800 --> 00:26:37,450
di luar sana yang membuktikan
bahwa, yep, kunci ini

643
00:26:37,450 --> 00:26:39,910
milik Amazon.com.

644
00:26:39,910 --> 00:26:42,330
Dan secara arsitektural,
jenis kesalahan

645
00:26:42,330 --> 00:26:46,937
atau model ancaman buruk
yang diasumsikan mereka

646
00:26:46,937 --> 00:26:49,020
adalah apakah semua otoritas sertifikat ini
akan dapat dipercaya.

647
00:26:49,020 --> 00:26:50,805
Mereka tidak akan pernah berbuat kesalahan.

648
00:26:50,805 --> 00:26:52,180
Dan faktanya,
cara sistem bekerja

649
00:26:52,180 --> 00:26:54,710
adalah bahwa ada ratusan
otoritas sertifikat ini di luar sana.

650
00:26:54,710 --> 00:26:58,390
Otoritas pos India,
saya rasa, memiliki otoritas sertifikat.

651
00:26:58,390 --> 00:27:00,420
Pemerintah Tiongkok memiliki otoritas sertifikat.

652
00:27:00,420 --> 00:27:04,780
Banyak entitas adalah otoritas
setifikat dalam rancangan ini.

653
00:27:04,780 --> 00:27:06,870
Dan salah satu dari mereka dapat
membuat sertifikat

654
00:27:06,870 --> 00:27:09,667
untuk nama host
atau domain apapun.

655
00:27:09,667 --> 00:27:11,750
Dan sebagai konsekuensinya, apa
yang terjadi jika Anda orang jahat,

656
00:27:11,750 --> 00:27:14,750
jika Anda ingin membobol Gmail
atau jika Anda ingin meniru

657
00:27:14,750 --> 00:27:16,739
situs Gmail, Anda
hanya perlu membobol

658
00:27:16,739 --> 00:27:18,280
salah satu dari
otoritas seritifikat ini.

659
00:27:18,280 --> 00:27:20,450
Dan ternyata
tautan terlemah adalah mungkin

660
00:27:20,450 --> 00:27:23,170
beberapa otoritas buruk yang berada
di suatu tempat di,

661
00:27:23,170 --> 00:27:26,730
sebagaimana Anda tahu,
negara yang tidak terlalu terkini.

662
00:27:26,730 --> 00:27:27,760
Siapa tahu, betul?

663
00:27:27,760 --> 00:27:31,170
Dan sebagai konsekuensinya, ini
mungkin asumsi yang buruk

664
00:27:31,170 --> 00:27:33,216
untuk membangun suatu sistem--
atau ini adalah suatu ide yang buruk

665
00:27:33,216 --> 00:27:34,840
untuk membuat suatu sistem
di dalam asumsi

666
00:27:34,840 --> 00:27:38,870
bahwa Anda akan mengelola
seluruh 300 otoritas

667
00:27:38,870 --> 00:27:42,420
sertifikat yang tersebar di seluruh
dunia dengan benar-benar aman.

668
00:27:42,420 --> 00:27:44,560
Namun begitu, asumsi tersebut adalah
asumsi yang mendasari

669
00:27:44,560 --> 00:27:49,090
mekanisme kamanan dari
protokol SSL yang digunakan oleh

670
00:27:49,090 --> 00:27:51,900
peramban saat ini.

671
00:27:51,900 --> 00:27:56,040
Dan terdapat, saya kira,
contoh-contoh lainnya

672
00:27:56,040 --> 00:27:58,510
yang mungkin tidak pernah
Anda pikirkan.

673
00:27:58,510 --> 00:28:04,080
Contoh menarik lainnya dari 1980an
adalah DARPA.

674
00:28:04,080 --> 00:28:07,090
Agen pertahanan ini,
pada waktu itu,

675
00:28:07,090 --> 00:28:10,310
benar-benar ingin membangun
sistem operasi yang aman.

676
00:28:10,310 --> 00:28:13,646
Dan mereka benar-benar berusaha
untuk mendapatkan

677
00:28:13,646 --> 00:28:15,270
sekumpulan universitas
dan peneliti

678
00:28:15,270 --> 00:28:17,840
untuk membangun prototipe SO (Sistem Operasi) yang aman.

679
00:28:17,840 --> 00:28:19,520
Dan kemudian mereka sebenarnya
membuat kelompok kedua,

680
00:28:19,520 --> 00:28:23,516
seperti sekelompok orang jahat
yang berpura-pura menjadi penyerang,

681
00:28:23,516 --> 00:28:25,890
dan memberitahu mereka, yah,
bobollah sistem operasi yang

682
00:28:25,890 --> 00:28:26,930
aman ini dengan cara apapun yang Anda bisa.

683
00:28:26,930 --> 00:28:29,300
Kita sebenarnya ingin
tahu, apakah itu aman?

684
00:28:29,300 --> 00:28:32,322
Dan beberapa dari cara
mengejutkan yang digunakan

685
00:28:32,322 --> 00:28:33,530
mereka untuk membobol sistem cukup menarik.

686
00:28:33,530 --> 00:28:36,960
Salah satunya adalah ada
sebuah kelompok penelitian

687
00:28:36,960 --> 00:28:39,072
SO ini yang terlihat memiliki
SO yang benar-benar aman,

688
00:28:39,072 --> 00:28:40,030
tapi berhasil dibobol.

689
00:28:40,030 --> 00:28:42,940
Dan yang terjadi adalah
server tempat di mana kode

690
00:28:42,940 --> 00:28:44,190
sumber sistem operasi
disimpan

691
00:28:44,190 --> 00:28:46,070
adalah di sebuah mesin
di kantor seseorang

692
00:28:46,070 --> 00:28:47,270
yang sangat tidak aman.

693
00:28:47,270 --> 00:28:48,660
Namun server tersebut memiliki
seluruh kode sumbernya.

694
00:28:48,660 --> 00:28:50,500
Jadi orang jahat itu
masuk ke server tersebut.

695
00:28:50,500 --> 00:28:51,850
Server tersebut tidak terlindungi dengan baik.

696
00:28:51,850 --> 00:28:53,340
(Orang itu) mengubah kode sumber
dari sistem operasi

697
00:28:53,340 --> 00:28:54,690
untuk membuat sebuah celah (backdoor).

698
00:28:54,690 --> 00:28:57,964
Lalu, saat peneliti
membangun sistem operasi mereka,

699
00:28:57,964 --> 00:28:59,130
sistem tersebut memiliki celah.

700
00:28:59,130 --> 00:29:00,755
Dan orang-orang jahat
dapat masuk.

701
00:29:00,755 --> 00:29:03,530
Jadi Anda benar-benar harus memikirkan
semua kemungkinan

702
00:29:03,530 --> 00:29:05,800
dari asumsi
yang Anda buat tentang

703
00:29:05,800 --> 00:29:07,440
dari mana perangkat lunak Anda
berasal,

704
00:29:07,440 --> 00:29:09,630
tentang bagaimana orang jahat
dapat masuk,

705
00:29:09,630 --> 00:29:14,150
untuk memastikan sistem Anda
benar-benar aman.

706
00:29:14,150 --> 00:29:18,160
Dan ada banyak contoh lain
dalam catatan kuliah, jika Anda mau.

707
00:29:18,160 --> 00:29:19,240
Jadi saya menggunakan anekdot.

708
00:29:19,240 --> 00:29:20,910
Anda dapat membacanya di sana.

709
00:29:23,750 --> 00:29:28,580
Mungkin masalah yang paling banyak
yang muncul,

710
00:29:28,580 --> 00:29:30,710
tentu saja, ada di dalam
mekanisme.

711
00:29:30,710 --> 00:29:33,290
Dan sebagian, itu
dikarenakan mekanisme

712
00:29:33,290 --> 00:29:35,490
adalah bagian yang paling rumit
dari cerita ini.

713
00:29:35,490 --> 00:29:39,225
Mekanisme adalah keseluruhan dari semua
perangkat lunak dan perangkat keras

714
00:29:39,225 --> 00:29:41,000
dan semua komponen sistem
semacam itu

715
00:29:41,000 --> 00:29:45,400
yang membentuk apa yang mencoba untuk
memaksakan kebijakan keamanaan Anda.

716
00:29:45,400 --> 00:29:49,960
Dan tidak ada akhir dari
di mana mekanisme bisa gagal.

717
00:29:49,960 --> 00:29:55,070
Dan, sebagai akibatnya,
sebagian besar kuliah ini

718
00:29:55,070 --> 00:29:57,760
akan lebih memfokuskan
pada mekanisme

719
00:29:57,760 --> 00:30:00,480
dan bagaimana Anda membuat
mekanisme yang aman,

720
00:30:00,480 --> 00:30:04,450
yang menyediakan pemaksaan
kebijakan keamanan yang benar.

721
00:30:04,450 --> 00:30:06,930
Dan kita akan berbicara tentang model
ancaman dan kebijakan juga.

722
00:30:06,930 --> 00:30:12,010
Namun ternyata lebih mudah
untuk membuat pernyataan yang bersih,

723
00:30:12,010 --> 00:30:14,300
yang agak tajam
tentang mekanisme dan cara

724
00:30:14,300 --> 00:30:18,100
mereka bekerja dan tidak bekerja, yang
berlawanan dengan kebijakan dan model

725
00:30:18,100 --> 00:30:20,420
ancaman yang, sesungguhnya,
Anda harus cari tahu

726
00:30:20,420 --> 00:30:22,190
bagaimana memasukkan hal-hal tersebut ke dalam
sebuah konteks tertentu

727
00:30:22,190 --> 00:30:24,980
di mana Anda menggunakan sebuah sistem.

728
00:30:24,980 --> 00:30:30,320
Jadi mari kita lihat beberapa contoh dari,
saya rasa, kesalahan mekanisme.

729
00:30:30,320 --> 00:30:33,280
Salah satu yang mungkin kalian pernah dengar
dalam beberapa hari terakhir

730
00:30:33,280 --> 00:30:38,380
adalah sebuah masalah dalam mekanisme
keamanan di infrastruktur awan (cloud) milik Apple

731
00:30:38,380 --> 00:30:39,610
yang disebut iCloud.

732
00:30:42,820 --> 00:30:45,430
Yah sebenarnya, siapapun
dari Anda yang memiliki sebuah iPhone

733
00:30:45,430 --> 00:30:47,450
mungkin menggunakan
layanan iCloud.

734
00:30:47,450 --> 00:30:49,690
Mereka pada dasarnya menyediakan
tempat penyimpanan untuk berkas

735
00:30:49,690 --> 00:30:53,290
dan membantu Anda menemukan iPhone Anda
jika Anda kehilangannya, dan mungkin

736
00:30:53,290 --> 00:30:55,450
banyak fitur berguna lainnya.

737
00:30:55,450 --> 00:30:58,780
Dan saya pikir hal tersebut berhubungan
dengan layanan me.com 

738
00:30:58,780 --> 00:31:03,150
yang terlibat dalam skema ini
beberapa tahun yang lalu.

739
00:31:03,150 --> 00:31:04,840
Dan masalah
yang ditemukan seseorang

740
00:31:04,840 --> 00:31:08,270
di layanan iCloud ini
adalah bahwa mereka

741
00:31:08,270 --> 00:31:11,960
tidak menerapkan mekanisme 
yang sama di semua antarmuka.

742
00:31:11,960 --> 00:31:13,540
OK, jadi seperti apa
iCloud?

743
00:31:13,540 --> 00:31:18,410
Yah, pada dasarnya iCloud menyediakan
banyak layanan untuk

744
00:31:18,410 --> 00:31:19,650
sekumpulan akun yang sama.

745
00:31:19,650 --> 00:31:23,050
Jadi mungkin Anda punya tempat
penyimpanan berkas di iCloud.

746
00:31:23,050 --> 00:31:26,087
Mungkin Anda telah 
membagikan foto Anda.

747
00:31:26,087 --> 00:31:27,420
Mungkin Anda mempunyai antarmuka lainnya.

748
00:31:27,420 --> 00:31:28,850
Dan salah satu
antarmuka di dalam iCloud--

749
00:31:28,850 --> 00:31:30,475
ini semuanya
ada di API berbeda

750
00:31:30,475 --> 00:31:35,130
yang mereka sediakan-- adalah
fitur untuk menemukan iPhone saya,

751
00:31:35,130 --> 00:31:36,730
saya pikir.

752
00:31:36,730 --> 00:31:39,090
Dan semua antarmuka ini
ingin memastikan

753
00:31:39,090 --> 00:31:42,580
bahwa Anda pengguna yang sebenarnya,
Anda diautentikasi dengan benar.

754
00:31:42,580 --> 00:31:45,050
Dan sayangnya,
para pengembang dari

755
00:31:45,050 --> 00:31:48,190
seluruh sistem iCloud ini, seperti yang Anda tahu
ini merupakan sebuah perangkat lunak yang sangat besar.

756
00:31:48,190 --> 00:31:51,310
Saya yakin banyak
pengembang yang bekerja di sini.

757
00:31:51,310 --> 00:31:53,070
Namun pada antarmuka
tertentu ini,

758
00:31:53,070 --> 00:31:55,480
yaitu antarmuka untuk
temukan iPhone saya, ketika

759
00:31:55,480 --> 00:31:58,510
Anda mencoba untuk masuk dengan
sebuah username dan kata sandi,

760
00:31:58,510 --> 00:32:02,420
mereka tidak memantau
berapa banyak Anda mencoba masuk.

761
00:32:02,420 --> 00:32:05,640
Dan alasannya adalah penting
seperti yang sudah saya sebutkan sebelumnya,

762
00:32:05,640 --> 00:32:07,930
manusia tidak sebaik itu dalam
memilih kata sandi yang baik.

763
00:32:07,930 --> 00:32:10,920
Jadi sebenarnya membuat suatu sistem
yang mengautentikasi pengguna

764
00:32:10,920 --> 00:32:12,490
dengan kata sandi itu cukup rumit.

765
00:32:12,490 --> 00:32:14,820
Kita sebetulnya akan membaca keseluruhan
paper mengenai hal ini nantinya.

766
00:32:14,820 --> 00:32:19,290
Namun satu strategi yang baik
adalah, mungkin ada

767
00:32:19,290 --> 00:32:22,170
satu juta kata sandi di luar
sana yang akan bertanggung jawab

768
00:32:22,170 --> 00:32:24,180
untuk 50% dari akun yang ada.

769
00:32:24,180 --> 00:32:26,420
Jadi jika Anda dapat menebak,
membuat jutaan percobaan

770
00:32:26,420 --> 00:32:28,900
pada akun
seseorang, maka ada

771
00:32:28,900 --> 00:32:31,150
sebuah kesempatan bagus Anda akan mendapatkan
kata sandi mereka karena orang-orang

772
00:32:31,150 --> 00:32:33,060
sebetulnya memilih
kata sandi yang dapat ditebak.

773
00:32:33,060 --> 00:32:34,494
Dan satu cara untuk
mencoba menggagalkan hal ini

774
00:32:34,494 --> 00:32:36,160
adalah memastikan bahwa
sistem Anda tidak

775
00:32:36,160 --> 00:32:38,670
memperbolehkan seseorang untuk
mencoba login ke sebuah akun

776
00:32:38,670 --> 00:32:39,870
dalam jumlah tertentu.

777
00:32:39,870 --> 00:32:42,220
Mungkin setelah tiga
atau 10 kali mencoba, Anda

778
00:32:42,220 --> 00:32:44,950
seharusnya mengatakan, baiklah,
Anda sudah cukup mencoba.

779
00:32:44,950 --> 00:32:45,740
Waktu habis.

780
00:32:45,740 --> 00:32:48,360
Anda dapat mencoba lagi dalam
10 menit atau dalam satu jam.

781
00:32:48,360 --> 00:32:50,870
Dan dengan cara ini Anda benar-benar
memperlambat si penyerang.

782
00:32:50,870 --> 00:32:54,460
Jadi mereka hanya bisa mencoba
beberapa tebakan dalam sehari,

783
00:32:54,460 --> 00:32:56,217
alih-alih jutaan tebakan.

784
00:32:56,217 --> 00:32:58,300
Dan sebagai konsekuensinya, bahkan
jika Anda kata sandi Anda

785
00:32:58,300 --> 00:33:00,550
tidak cukup baik, akan cukup sulit
bagi seseorang

786
00:33:00,550 --> 00:33:01,570
untuk menebaknya.

787
00:33:01,570 --> 00:33:06,990
Apa yang akan terjadi adalah bahwa iCloud
memiliki pencegahan penebakan

788
00:33:06,990 --> 00:33:10,210
kata sandi atau, pada dasarnya,
mempersulit penebakan, pada beberapa antarmuka,

789
00:33:10,210 --> 00:33:12,730
seperti jika Anda mencoba masuk
lewat antarmuka lain

790
00:33:12,730 --> 00:33:15,130
dan Anda gagal 10 kali,
antarmuka tersebut akan mengatakan, yah, maaf.

791
00:33:15,130 --> 00:33:17,150
Anda harus menunggu
sampai Anda mencoba lagi.

792
00:33:17,150 --> 00:33:18,710
Namun dalam antarmuka untuk
temukan iPhone saya,

793
00:33:18,710 --> 00:33:19,669
mereka lupa pengecekan ini.

794
00:33:19,669 --> 00:33:21,335
Mungkin, Anda tahu,
seseorang hanya

795
00:33:21,335 --> 00:33:23,300
lupa untuk memanggil fungsi
ini dalam API ini.

796
00:33:23,300 --> 00:33:26,867
Namun hasilnya adalah, untuk
sekumpulan akun yang sama,

797
00:33:26,867 --> 00:33:28,950
orang jahat kini dapat
menebak kata sandi Anda

798
00:33:28,950 --> 00:33:32,890
melalui antarmuka ini
dengan jutaan percobaan per hari

799
00:33:32,890 --> 00:33:35,340
dengan mudahnya, karena hal ini hanya
terbatas pada seberapa cepat mereka

800
00:33:35,340 --> 00:33:37,452
dapat mengirim paket
ke perangkat iCloud ini.

801
00:33:37,452 --> 00:33:39,160
Dan mereka mungkin dapat
menebak kata sandi Anda

802
00:33:39,160 --> 00:33:43,960
dengan akurasi yang cukup baik, atau
dengan tingkat keberhasilan yang cukup baik,

803
00:33:43,960 --> 00:33:46,780
setelah membuat banyak tebakan.

804
00:33:46,780 --> 00:33:48,890
Dan hal ini menyebabkan beberapa
pembobolan, yang sangat disayangkan.

805
00:33:48,890 --> 00:33:51,660
Dan data rahasia orang-orang
dicuri

806
00:33:51,660 --> 00:33:54,870
dari layanan iCloud ini.

807
00:33:54,870 --> 00:33:59,621
Jadi ini adalah contoh
di mana Anda memiliki kebijakan yang tepat.

808
00:33:59,621 --> 00:34:01,120
Hanya pengguna dan
kata sandi yang benar

809
00:34:01,120 --> 00:34:02,632
yang akan memberi Anda
akses ke file.

810
00:34:02,632 --> 00:34:04,090
Anda bahkan memiliki
model ancaman yang tepat

811
00:34:04,090 --> 00:34:06,810
yang, yah, mungkin dapat orang jahat
tebak kata sandinya.

812
00:34:06,810 --> 00:34:09,370
Jadi kita harus mengurangi
batas jumlah percobaan.

813
00:34:09,370 --> 00:34:12,250
Namun dia hanya mengacau, seperti
mekanismenya memiliki kesalahan di dalamnya.

814
00:34:12,250 --> 00:34:15,239
Dia hanya lupa untuk memastikan
kebijakan dan mekanisme yang benar ini

815
00:34:15,239 --> 00:34:16,280
di beberapa antarmuka.

816
00:34:16,280 --> 00:34:19,520
Dan hal ini muncul lagi dan
lagi dalam sistem,

817
00:34:19,520 --> 00:34:24,060
di mana baru saja ada kesalahan dan
hal itu memiliki dampak yang cukup drastis

818
00:34:24,060 --> 00:34:27,000
pada keamanan sistem
secara keseluruhan.

819
00:34:27,000 --> 00:34:28,960
Apakah ini masuk akal?

820
00:34:28,960 --> 00:34:30,320
Apakah ada pertanyaan sejauh ini?

821
00:34:33,290 --> 00:34:34,630
Baiklah.

822
00:34:34,630 --> 00:34:35,260
OK.

823
00:34:35,260 --> 00:34:39,149
Jadi contoh lainnya-- ini
adalah semacam contoh ketika Anda

824
00:34:39,149 --> 00:34:42,982
lupa untuk memeriksa
percobaan menebak kata sandi.

825
00:34:42,982 --> 00:34:44,690
Ada berbagai macam
hal lain yang bisa saja Anda lupakan.

826
00:34:44,690 --> 00:34:47,830
Anda bisa lupa untuk memeriksa
kontrol akses secara keseluruhan.

827
00:34:47,830 --> 00:34:53,179
Jadi salah satu contoh adalah, Citibank
memiliki sebuah situs web-- sebenarnya, masih

828
00:34:53,179 --> 00:34:57,150
mempunyai sebuah situs web yang memperbolehkan Anda
untuk melihat informasi akun

829
00:34:57,150 --> 00:34:58,280
kartu kredit milik Anda.

830
00:34:58,280 --> 00:34:59,560
Jadi jika Anda memiliki sebuah kartu
kredit Citibank,

831
00:34:59,560 --> 00:35:00,660
Anda pergi ke situs web ini,
maka situs tersebut akan memberi tahu Anda,

832
00:35:00,660 --> 00:35:01,993
yah, Anda memiliki kartu kredit ini.

833
00:35:01,993 --> 00:35:04,160
Ini adalah semua tagihannya,
semua barang bagus ini.

834
00:35:04,160 --> 00:35:08,480
Dan beberapa tahun lalu
cara kerjanya adalah Anda mengunjungi

835
00:35:08,480 --> 00:35:12,710
sebuah situs, Anda mengisikan
nama pengguna dan kata sandi,

836
00:35:12,710 --> 00:35:15,630
dan Anda dialihkan
ke URL lain,

837
00:35:15,630 --> 00:35:18,130
yang ternyata adalah sesuatu yang, saya
tidak tahu, saya menebaknya,

838
00:35:18,130 --> 00:35:23,190
tapi pada dasarnya seperti
citi.com/account?id= Anda tahu,

839
00:35:23,190 --> 00:35:26,640
apapun, satu dua tiga empat.

840
00:35:26,640 --> 00:35:29,422
Dan ternyata beberapa
orang menemukan bahwa, baik,

841
00:35:29,422 --> 00:35:30,880
jika Anda mengganti nomor
ini, Anda bisa

842
00:35:30,880 --> 00:35:33,910
mendapatkan akun milik seseorang.

843
00:35:33,910 --> 00:35:37,510
Dan tidak begitu jelas
bagaimana memikirkan hal ini.

844
00:35:37,510 --> 00:35:40,010
Salah satu kemungkinannya adalah orang-orang
ini sudah berpikir dengan benar,

845
00:35:40,010 --> 00:35:43,020
tetapi mereka, sekali lagi, lupa
memeriksa fungsi di halaman

846
00:35:43,020 --> 00:35:46,646
akun ini, tidak hanya apakah saya
memiliki nomor ID yang valid,

847
00:35:46,646 --> 00:35:48,520
tetapi juga nomor ID
dari seseorang yang

848
00:35:48,520 --> 00:35:50,480
sekarang sedang masuk.

849
00:35:50,480 --> 00:35:51,950
Ini pemeriksaan penting bagi saya.

850
00:35:51,950 --> 00:35:53,759
Namun pemeriksaan tersebut mudah dilupakan.

851
00:35:53,759 --> 00:35:55,800
Hal lainnya adalah, mungkin
orang-orang ini berpikir

852
00:35:55,800 --> 00:35:56,932
tidak, tidak ada yang bisa mengakses URL.

853
00:35:56,932 --> 00:35:58,640
Mungkin mereka memiliki
model ancaman yang buruk, bukan?

854
00:35:58,640 --> 00:36:00,450
mungkin mereka
berpikir, URLnya--

855
00:36:00,450 --> 00:36:02,820
jika saya tidak menampilkan URL ini,
tidak akan ada yang bisa mengkliknya.

856
00:36:02,820 --> 00:36:04,190
Ini seperti model ancaman yang buruk.

857
00:36:04,190 --> 00:36:07,480
jadi mungkin itu-- sulit
untuk mengatakan dengan tepat apa

858
00:36:07,480 --> 00:36:08,160
yang salah.

859
00:36:08,160 --> 00:36:10,280
Namun bagaimanapun,
kesalahan ini bisa terjadi.

860
00:36:10,280 --> 00:36:12,860
Dan mereka sering muncul.

861
00:36:12,860 --> 00:36:17,620
Sangat mudah untuk mempunyai
kesalahan yang kecil, yang tampaknya seperti kesalahan

862
00:36:17,620 --> 00:36:24,430
dalam mekanisme anda yang menyebabkan
konsekuensi yang sangat disayangkan.

863
00:36:24,430 --> 00:36:28,150
Contoh lain yang tidak terkait
pengecekan yang terlupakan

864
00:36:28,150 --> 00:36:30,990
adalah masalah yang 
muncul di ponsel

865
00:36:30,990 --> 00:36:33,810
Android beberapa bulan lalu.

866
00:36:33,810 --> 00:36:38,070
Mungkin saya akan 
menggunakan papan yang di sini.

867
00:36:38,070 --> 00:36:42,110
Jadi masalahnya berhubungan dengan 
Bitcoin, yang mana-- yah,

868
00:36:42,110 --> 00:36:44,480
saya yakin kalian pernah mendengar--
sistem mata uang elektronik

869
00:36:44,480 --> 00:36:47,770
yang cukup
populer belakangan ini.

870
00:36:47,770 --> 00:36:54,650
Dan cara Bitcoin
bekerja, pada level atas,

871
00:36:54,650 --> 00:36:58,710
adalah dengan mengasosiasikan
saldo Bitcoin Anda

872
00:36:58,710 --> 00:37:00,900
dengan sebuah kunci privat.

873
00:37:00,900 --> 00:37:03,000
Dan jika kalian memiliki
kunci privat seseorang

874
00:37:03,000 --> 00:37:05,770
kalian tentu saja bisa,
menghabiskan Bitcoin mereka.

875
00:37:05,770 --> 00:37:10,610
Jadi keamanan dari Bitcoin
cukup bergantung

876
00:37:10,610 --> 00:37:13,410
pada tidak ada orang lain yang mengetahui
kunci privat Anda.

877
00:37:13,410 --> 00:37:15,720
Ini cukup mirip dengan sebuah kata sandi,
kecuali ini jauh lebih

878
00:37:15,720 --> 00:37:18,397
penting, karena orang dapat
membuat banyak tebakan

879
00:37:18,397 --> 00:37:19,230
pada kunci privat Anda.

880
00:37:19,230 --> 00:37:21,396
Dan tidak ada server sungguhan
yang memeriksa kunci Anda.

881
00:37:21,396 --> 00:37:22,390
Ini hanya kriptografi.

882
00:37:22,390 --> 00:37:24,717
Jadi banyak mesin yang bisa mencoba
membuat banyak tebakan

883
00:37:24,717 --> 00:37:25,550
terhadap kunci privat Anda.

884
00:37:25,550 --> 00:37:28,380
Dan jika mereka berhasil menebaknya, maka
mereka dapat mengirimkan Bitcoin Anda

885
00:37:28,380 --> 00:37:30,220
ke orang lain.

886
00:37:30,220 --> 00:37:32,340
Dan sebagai konsekuensinya, ini
sangatlah penting

887
00:37:32,340 --> 00:37:34,910
bagi Anda untuk membangkitkan
kunci yang baik dan acak

888
00:37:34,910 --> 00:37:36,980
sehingga tidak ada yang bisa menebaknya.

889
00:37:36,980 --> 00:37:41,220
Dan ada orang-orang yang menggunakan
Bitcoin di Android.

890
00:37:41,220 --> 00:37:45,450
Dan aplikasi Android untuk Bitcoin
mendapatkan nilai acak

891
00:37:45,450 --> 00:37:51,210
untuk kunci ini dengan menggunakan
API Java yang bernama SecureRandom(),

892
00:37:51,210 --> 00:37:56,040
yang terdengar hebat, tetapi seperti
yang orang-orang ketahui, yah, OK.

893
00:37:56,040 --> 00:37:59,080
Jadi apa itu, benar, API tersebut
tidak benar-benar mendapatkan nilai acak yang sesungguhnya.

894
00:37:59,080 --> 00:38:00,800
Di dalamnya, ada
konstruksi ini

895
00:38:00,800 --> 00:38:04,090
yang disebut dengan Pseudorandom (acak semu)

896
00:38:04,090 --> 00:38:07,217
atau PRNG yang, diberi
nilai bibit tertentu,

897
00:38:07,217 --> 00:38:09,540
seperti Anda mungkin
mendapatkan beberapa ratus

898
00:38:09,540 --> 00:38:12,400
bit acak dan Anda
memberikannya ke PRNG,

899
00:38:12,400 --> 00:38:15,410
Anda bisa terus memintanya untuk
nilai yang lebih acak dan mengekspansi

900
00:38:15,410 --> 00:38:19,660
dari bit acak ini menjadi bit acak
sebanyak yang Anda inginkan.

901
00:38:19,660 --> 00:38:22,126
Jadi Anda melihatnya
pada awalnya, dan kemudian Anda

902
00:38:22,126 --> 00:38:24,000
dapat membangkitkan bit acak
sebanyak mungkin yang Anda inginkan.

903
00:38:24,000 --> 00:38:26,581
Dan untuk berbagai alasan kriptografi
yang tidak akan saya jelaskan di sini,

904
00:38:26,581 --> 00:38:27,330
hal itu sebenarnya bekerja.

905
00:38:27,330 --> 00:38:30,030
Jika Anda memberinya beberapa
ratus bit acak yang sangat bagus

906
00:38:30,030 --> 00:38:32,070
di awal, akan sangat sulit
bagi orang lain

907
00:38:32,070 --> 00:38:37,380
untuk memprediksi apa nilai
pseudorandom yang dibangkitkan.

908
00:38:37,380 --> 00:38:40,300
Namun masalahnya adalah
bahwa library Java ini

909
00:38:40,300 --> 00:38:41,840
memiliki sebuah kesalahan kecil di dalamnya.

910
00:38:41,840 --> 00:38:44,980
Di dalam beberapa
kondisi, library tersebut lupa

911
00:38:44,980 --> 00:38:46,860
untuk menginisialisasi
PRNG dengan bibit,

912
00:38:46,860 --> 00:38:50,022
jadi semuanya hanya bernilai nol,
yang berarti setiap orang

913
00:38:50,022 --> 00:38:51,730
dapat mengetahui
nomor acak Anda.

914
00:38:51,730 --> 00:38:53,120
Jika mereka memulai dengan
nol, mereka akan

915
00:38:53,120 --> 00:38:54,757
menghasilkan angka acak
yang sama seperti Anda,

916
00:38:54,757 --> 00:38:57,090
yang berarti mereka akan menghasilkan
kunci privat yang sama dengan Anda.

917
00:38:57,090 --> 00:38:59,190
Jadi mereka dapat membuat
kunci privat yang sama

918
00:38:59,190 --> 00:39:01,120
dan mengirimkan Bitcoin Anda.

919
00:39:01,120 --> 00:39:05,400
Jadi ini, sekali lagi,
kesalahan kecil atau tidak kecil,

920
00:39:05,400 --> 00:39:08,320
tergantung pada, saya kira,
siapa yang bertanya.

921
00:39:08,320 --> 00:39:10,000
Namun tetap saja, kan?

922
00:39:10,000 --> 00:39:12,500
Contoh lain dari kesalahan
kecil pemrograman

923
00:39:12,500 --> 00:39:14,790
yang mengarah
ke hasil yang sangat parah.

924
00:39:14,790 --> 00:39:17,410
Banyak orang yang saldo
Bitcoin-nya dicuri

925
00:39:17,410 --> 00:39:19,400
karena kelemahan ini.

926
00:39:19,400 --> 00:39:21,920
Tentu saja, perbaikannya
cukup sederhana di tingkatan tertentu.

927
00:39:21,920 --> 00:39:23,360
Anda mengubah
implementasi Java

928
00:39:23,360 --> 00:39:28,270
dari SecureRandom() untuk selalu
memberi bibit PRNG ini dengan bit

929
00:39:28,270 --> 00:39:29,210
masukan acak.

930
00:39:29,210 --> 00:39:31,300
Dan kemudian, semoga,
Anda dalam kondisi yang baik.

931
00:39:31,300 --> 00:39:36,532
Namun tetap saja, itu contoh lain
dari kegagalan mekanisme.

932
00:39:36,532 --> 00:39:37,174
Ya?

933
00:39:37,174 --> 00:39:39,424
AUDIENS: Hanya untuk memperjelas,
apakah ini adalah serangan yang berbeda

934
00:39:39,424 --> 00:39:42,096
dari keacakan tanda tangan
dengan algoritme DSA?

935
00:39:42,096 --> 00:39:42,970
PROFESOR: Yah begitulah.

936
00:39:42,970 --> 00:39:44,810
Jadi masalah sebenarnya
sedikit lebih

937
00:39:44,810 --> 00:39:46,310
rumit, dari
yang Anda maksud.

938
00:39:46,310 --> 00:39:48,700
Masalahnya, bahkan
jika Anda tidak membangkitkan

939
00:39:48,700 --> 00:39:51,140
kunci Anda di perangkat
Android pada awalnya,

940
00:39:51,140 --> 00:39:56,150
skema tanda tangan tertentu
yang digunakan oleh Bitcoin

941
00:39:56,150 --> 00:39:59,110
mengasumsikan bahwa setiap kali Anda
membuat tanda tangan baru

942
00:39:59,110 --> 00:40:01,310
dengan kunci itu, Anda
menggunakan sesuatu yang baru, apa yang

943
00:40:01,310 --> 00:40:03,290
disebut dengan nonce, untuk
membangkitkan tanda tangan itu.

944
00:40:03,290 --> 00:40:07,270
Dan jika Anda pernah membuat dua
tanda tangan dengan nonce yang sama,

945
00:40:07,270 --> 00:40:09,544
maka seseorang dapat menebak
apa kunci Anda.

946
00:40:09,544 --> 00:40:10,710
Cerita ini cukup mirip.

947
00:40:10,710 --> 00:40:12,270
Namun detailnya
sedikit berbeda.

948
00:40:12,270 --> 00:40:14,310
Jadi yah, bahkan jika Anda sebenarnya
membuat kunci Anda di suatu tempat

949
00:40:14,310 --> 00:40:16,726
lain dan kunci Anda sangat bagus,
maka kapan pun Anda

950
00:40:16,726 --> 00:40:19,840
membangkitkan sebuah tanda tangan,
Anda akan--

951
00:40:19,840 --> 00:40:23,190
dan Anda membuat dua tanda tangan
dengan menggunakan nonce yang sama persis,

952
00:40:23,190 --> 00:40:26,650
atau nilai yang acak, seseorang
bisa menerapkan beberapa prinsip matematika

953
00:40:26,650 --> 00:40:30,270
ke tanda tangan Anda dan
mengekstraksi kunci publik Anda yang dikeluarkan

954
00:40:30,270 --> 00:40:30,770
darinya.

955
00:40:30,770 --> 00:40:34,240
Atau kunci pribadi,
yang lebih penting.

956
00:40:34,240 --> 00:40:35,140
Baiklah.

957
00:40:35,140 --> 00:40:40,610
Pertanyaan lain tentang masalah
ini, contohnya, dan sebagainya?

958
00:40:40,610 --> 00:40:41,690
Baiklah.

959
00:40:41,690 --> 00:40:46,570
Jadi saya rasa, satu hal yang ingin
saya tunjukkan adalah,

960
00:40:46,570 --> 00:40:48,400
yah, saat Anda
mulai menghargai,

961
00:40:48,400 --> 00:40:52,830
bahwa dalam keamanan komputer,
hampir setiap detail

962
00:40:52,830 --> 00:40:55,000
memiliki peluang yang sangat penting.

963
00:40:55,000 --> 00:40:58,390
Jika Anda mengacaukan sesuatu yang
tampaknya sangat tidak penting,

964
00:40:58,390 --> 00:41:00,780
seperti lupa memeriksa
sesuatu, atau ini,

965
00:41:00,780 --> 00:41:03,190
atau lupa 
menginisialisasi bibit acak,

966
00:41:03,190 --> 00:41:04,980
hal tersebut dapat menimbulkan
konsekuensi yang cukup dramatis

967
00:41:04,980 --> 00:41:07,010
untuk keseluruhan sistem.

968
00:41:07,010 --> 00:41:09,530
Dan Anda benar-benar harus
sangat jelas tentang,

969
00:41:09,530 --> 00:41:11,510
apa spesifikasi
sistem Anda?

970
00:41:11,510 --> 00:41:12,510
Apa yang dilakukannya?

971
00:41:12,510 --> 00:41:14,870
Sebenarnya apa saja
kasus tepi nya?

972
00:41:14,870 --> 00:41:17,170
Dan cara yang baik untuk
memikirkan tentang merusak sebuah sistem

973
00:41:17,170 --> 00:41:19,369
atau, sebaliknya, mencari tahu
apakah sistem Anda aman,

974
00:41:19,369 --> 00:41:20,910
adalah untuk mencoba
semua kasus tepi,

975
00:41:20,910 --> 00:41:23,950
seperti apa yang terjadi jika
masukan saya cukup besar?

976
00:41:23,950 --> 00:41:26,620
Atau apa masukan terbesar
atau masukan terkecilnya?

977
00:41:26,620 --> 00:41:28,980
Jenis sekumpulan masukan
apa yang paling aneh

978
00:41:28,980 --> 00:41:30,670
dari masukan yang dapat saya
sediakan untuk program saya

979
00:41:30,670 --> 00:41:34,250
dan memasukkan semuanya
ke dalam kasus ini

980
00:41:34,250 --> 00:41:38,960
Satu contoh dari ambiguitas ini,
sebuah contoh yang cukup bagus,

981
00:41:38,960 --> 00:41:44,850
untuk dipikirkan, adalah bagaimana
sertifikat SSL, lagi,

982
00:41:44,850 --> 00:41:49,202
pengkodean nama menjadi
sertifikat itu sendiri.

983
00:41:49,202 --> 00:41:51,160
Jadi ini adalah masalah yang
berbeda dari masalah tentang

984
00:41:51,160 --> 00:41:53,580
otoritas sertifikat untuk
dipercayai.

985
00:41:53,580 --> 00:41:57,470
Jadi sertifikat SSL ini adalah
sederet byte

986
00:41:57,470 --> 00:41:59,000
yang dikirimkan server web kepada Anda.

987
00:41:59,000 --> 00:42:01,200
Dan di dalam sertifikat
SSL ini

988
00:42:01,200 --> 00:42:04,340
adalah nama dari server
yang mana Anda terkoneksi,

989
00:42:04,340 --> 00:42:06,144
jadi sesuatu seperti Amazon.com.

990
00:42:06,144 --> 00:42:08,060
Anda tahu, Anda tidak bisa serta merta
menaruh byte tersebut.

991
00:42:08,060 --> 00:42:09,870
Anda harus menyandikannya
entah bagaimana dan menentukan bahwa, baiklah,

992
00:42:09,870 --> 00:42:10,536
ini adalah Amazon.com.

993
00:42:10,536 --> 00:42:12,860
Dan itu adalah 
akhir dari string.

994
00:42:12,860 --> 00:42:18,540
Jadi pada sertifikat SSL, mereka
menggunakan skema pengkodean tertentu

995
00:42:18,540 --> 00:42:24,290
yang menulis Amazon.com
dengan menuliskan terlebih dahulu

996
00:42:24,290 --> 00:42:26,394
jumlah byte
di dalam string.

997
00:42:26,394 --> 00:42:27,560
Jadi Anda menulis terlebih dahulu, OK.

998
00:42:27,560 --> 00:42:32,314
Yah, saya akan memiliki string 10
byte yang disebut Amazon.com.

999
00:42:35,679 --> 00:42:36,720
Itu sebenarnya 10 bytes.

1000
00:42:36,720 --> 00:42:36,990
Bagus.

1001
00:42:36,990 --> 00:42:37,510
Oke.

1002
00:42:37,510 --> 00:42:40,120
Jadi ini seperti-- di dalam
sertifikat SSL, di suatu tempat

1003
00:42:40,120 --> 00:42:44,160
di sana, ada byte "10" ini yang diikuti
oleh 10 byte data yang menyebutkan

1004
00:42:44,160 --> 00:42:45,170
apa nama hostnya.

1005
00:42:45,170 --> 00:42:48,840
Dan terdapat hal lain
setelah itu, dan sebelumnya.

1006
00:42:48,840 --> 00:42:50,810
Dan saat peramban mengambil
nya, yah, peramban

1007
00:42:50,810 --> 00:42:54,140
ditulis dalam bahasa C. Dan
cara C merepresentasikan string

1008
00:42:54,140 --> 00:42:56,660
adalah dengan mengakhirinya dengan nilai null.

1009
00:42:56,660 --> 00:42:59,350
Jadi dalam C, sebuah string tidak
mencatat panjangnya.

1010
00:42:59,350 --> 00:43:01,080
Sebagai gantinya, string memiliki seluruh byte data.

1011
00:43:01,080 --> 00:43:03,660
Dan akhir dari string
adalah byte bernilai 0.

1012
00:43:03,660 --> 00:43:07,110
Dan dalam C, Anda menuliskan hal tersebut dengan
sebuah \0 (garis miring terbalik dan nol).

1013
00:43:07,110 --> 00:43:08,740
Jadi ini ada dalam memori
di peramban Anda.

1014
00:43:11,340 --> 00:43:13,310
Di suatu tempat dalam memori 
terdapat string ini

1015
00:43:13,310 --> 00:43:15,951
yang berukuran 11 byte, sekarang, dengan 
tambahan nol di akhir.

1016
00:43:15,951 --> 00:43:17,700
Dan ketika peramban
menafsirkan string ini,

1017
00:43:17,700 --> 00:43:19,950
ia akan terus membaca sampai
ia melihat penanda dari

1018
00:43:19,950 --> 00:43:22,840
ujung string, yang merupakan byte nol.

1019
00:43:22,840 --> 00:43:24,000
OK.

1020
00:43:24,000 --> 00:43:26,330
Jadi, apa yang bisa salah?

1021
00:43:26,330 --> 00:43:28,751
Ada tebakan?

1022
00:43:28,751 --> 00:43:29,250
Ya?

1023
00:43:29,250 --> 00:43:31,575
AUDIENS: Anda memiliki nol
di tengah [TAK TERDENGAR]?

1024
00:43:31,575 --> 00:43:32,040
PROFESSOR: Iya.

1025
00:43:32,040 --> 00:43:32,510
Ini bagus.

1026
00:43:32,510 --> 00:43:33,009
Baiklah.

1027
00:43:33,009 --> 00:43:35,222
Jadi, ini sebenarnya merupakan
sedikit ketidaksesuaian

1028
00:43:35,222 --> 00:43:36,680
dalam hal bagaimana
orang ini merepresentasikan

1029
00:43:36,680 --> 00:43:37,850
string dengan orang ini.

1030
00:43:37,850 --> 00:43:41,530
Jadi contohnya, saya adalah 
pemilik domain foo.com.

1031
00:43:41,530 --> 00:43:45,731
Jadi saya dapat mendapatkan sertifikat
untuk apapun titik foo titik com.

1032
00:43:45,731 --> 00:43:50,568
Jadi yang dapat saya lakukan adalah meminta
sebuah sertifikat untuk nama

1033
00:43:50,568 --> 00:43:51,443
amazon.com0x.foo.com.

1034
00:43:57,325 --> 00:43:59,160
Itu adalah sebuah string yang sah.

1035
00:43:59,160 --> 00:44:00,730
Dia punya sekelompok byte.

1036
00:44:00,730 --> 00:44:03,710
Saya rasa 10, 11
12 13, 14, 15, 16,

1037
00:44:03,710 --> 00:44:05,830
terdapat 4 byte lagi, 20, benar?

1038
00:44:05,830 --> 00:44:10,020
Jadi ini adalah nama dengan 20 byte 
dengan 20 byte ini.

1039
00:44:10,020 --> 00:44:12,760
Jadi dulu, ketika Anda datang
ke sebuah otoritas sertifikat,

1040
00:44:12,760 --> 00:44:15,230
dalam banyak kasus, Anda dapat
berkata, hei, sayalah pemilik foo.com.

1041
00:44:15,230 --> 00:44:16,990
Berikan pada saya sertifikat
untuk benda ini.

1042
00:44:16,990 --> 00:44:19,660
Dan mereka sepenuhnya bersedia
untuk melakukannya karena itu

1043
00:44:19,660 --> 00:44:20,790
adalah subdomain dari foo.com.

1044
00:44:20,790 --> 00:44:22,750
Itu sepenuhnya milik Anda.

1045
00:44:22,750 --> 00:44:25,220
Namun kemudian, ketika sebuah peramban
menerima string ini

1046
00:44:25,220 --> 00:44:27,930
dan memuat string di dalam memori, yah,
yang dia lakukan adalah hal yang sama

1047
00:44:27,930 --> 00:44:28,830
dengan yang dilakukannya di sini.

1048
00:44:28,830 --> 00:44:30,839
Dia menyalin string tersebut.

1049
00:44:30,839 --> 00:44:31,714
amazon.com0x.foo.com.

1050
00:44:37,206 --> 00:44:40,700
Dia akan dengan patuh menambahkan
nilai nol di akhir string.

1051
00:44:40,700 --> 00:44:43,370
Tetapi setelah itu, ketika bagian lain
dari perangkat lunak peramban

1052
00:44:43,370 --> 00:44:47,510
mencoba untuk menafsirkan
string di lokasi memori ini,

1053
00:44:47,510 --> 00:44:50,722
dia akan membaca hingga menemukan
nilai nol dan berkata, oke,

1054
00:44:50,722 --> 00:44:51,930
itulah akhir dari string tersebut.

1055
00:44:51,930 --> 00:44:53,276
Jadi ini adalah Amazon.com.

1056
00:44:53,276 --> 00:44:54,630
Itu dia.

1057
00:44:54,630 --> 00:45:00,120
Jadi ketidaksesuaian semacam ini
antara bagaimana perangkat lunak C

1058
00:45:00,120 --> 00:45:03,070
dan bagaimana sertifikat SSL
merepresentasikan nama

1059
00:45:03,070 --> 00:45:05,800
menyebabkan beberapa
masalah keamanan yang disayangkan.

1060
00:45:05,800 --> 00:45:08,240
Masalah ini sebenarnya
ditemukan beberapa tahun

1061
00:45:08,240 --> 00:45:11,030
yang lalu oleh orang ini,
Moxie Marlinspike.

1062
00:45:11,030 --> 00:45:13,620
Tapi itu merupakan
pengamatan yang cukup cerdas.

1063
00:45:13,620 --> 00:45:17,470
Dan jenis bug pengkodean
semacam ini sebenarnya juga

1064
00:45:17,470 --> 00:45:20,470
cukup umum terjadi dalam
banyak perangkat lunak

1065
00:45:20,470 --> 00:45:24,030
karena, kecuali Anda sangat
rajin mengenai bagaimana Anda

1066
00:45:24,030 --> 00:45:27,090
mengkodekan hal-hal, mungkin ada
beberapa cara pengkodean yang berbeda.

1067
00:45:27,090 --> 00:45:28,547
Dan kapanpun ada
pertentangan,

1068
00:45:28,547 --> 00:45:30,880
ada kemungkinan orang jahat
dapat memanfaatkan ini.

1069
00:45:30,880 --> 00:45:32,421
Satu sistem berpikir
itu adalah nama yang bagus.

1070
00:45:32,421 --> 00:45:34,590
Yang lain berpikir itu
tidak, merupakan sesuatu yang lain.

1071
00:45:34,590 --> 00:45:36,870
Jadi ini adalah tempat yang cocok
untuk semacam menekan sistem

1072
00:45:36,870 --> 00:45:39,360
untuk melihat bagaimana sistem itu dapat rusak.

1073
00:45:39,360 --> 00:45:42,030
Apakah itu masuk akal?

1074
00:45:42,030 --> 00:45:42,530
Baiklah.

1075
00:45:42,530 --> 00:45:47,220
Jadi mungkin contoh terakhir
dari kegagalan mekanisme

1076
00:45:47,220 --> 00:45:51,090
yang akan saya bicarakan hari ini
adalah salah satu yang cukup populer.

1077
00:45:51,090 --> 00:45:52,910
Itu adalah masalah ini
atau buffer overflow.

1078
00:45:56,230 --> 00:45:59,380
Jadi beberapa dari kalian telah melihat ini,
atau setidaknya pada level tertentu,

1079
00:45:59,380 --> 00:46:01,860
dalam 6.033, jika Anda mengambil
mata kuliah S1 tersebut.

1080
00:46:01,860 --> 00:46:05,290
Tetapi bagi Anda yang sudah
lupa atau belum mengambil

1081
00:46:05,290 --> 00:46:07,540
nol tiga tiga, kita akan semacam
membahas buffer overflow

1082
00:46:07,540 --> 00:46:08,130
secara lebih detail.

1083
00:46:08,130 --> 00:46:10,463
Dan ini akan menjadi, sebenarnya,
cukup kritis untuk kalian,

1084
00:46:10,463 --> 00:46:12,826
karena lab satu seluruhnya
tentang buffer overflow.

1085
00:46:12,826 --> 00:46:14,200
Dan Anda akan
mengeksploitasi

1086
00:46:14,200 --> 00:46:19,710
kerentanan ini dalam sebuah
server web yang dapat dibilang nyata.

1087
00:46:19,710 --> 00:46:21,610
Jadi mari kita cari tahu,
apa pengaturannya?

1088
00:46:21,610 --> 00:46:23,300
Apa yang sedang kita bicarakan di sini?

1089
00:46:23,300 --> 00:46:25,470
Jadi pengaturan yang
akan kita pertimbangkan

1090
00:46:25,470 --> 00:46:30,330
adalah sebuah sistem yang memiliki,
anggap saja, sebuah server web.

1091
00:46:30,330 --> 00:46:34,510
Jadi apa yang kita punya adalah, kita punya
beberapa komputer di luar sana

1092
00:46:34,510 --> 00:46:36,540
yang mempunyai sebuah server web di atas nya.

1093
00:46:39,130 --> 00:46:41,200
Dan server web tersebut
adalah sebuah program yang

1094
00:46:41,200 --> 00:46:44,070
akan menerima koneksi
dari dunia luar,

1095
00:46:44,070 --> 00:46:47,480
menerima permintaan-- yang pada
dasarnya hanyalah paket-paket--

1096
00:46:47,480 --> 00:46:51,820
dan entah bagaimana caranya memproses mereka,
dan mungkin, melakukan beberapa pengecekan.

1097
00:46:51,820 --> 00:46:54,174
Kalau itu adalah sebuah URL
ilegal, atau mereka sedang

1098
00:46:54,174 --> 00:46:56,590
mencoba untuk mengakses sebuah file
yang tidak boleh diakses oleh mereka,

1099
00:46:56,590 --> 00:46:58,381
maka server web akan
mengembalikan sebuah pesan kesalahan.

1100
00:46:58,381 --> 00:47:00,400
Tapi jika tidak demikian, maka dia
akan mengakses beberapa file,

1101
00:47:00,400 --> 00:47:04,040
mungkin pada disk, dan
mengirimkan mereka kembali

1102
00:47:04,040 --> 00:47:06,990
sebagai semacam balasan.

1103
00:47:06,990 --> 00:47:10,320
Jadi ini adalah sebuah gambaran umum
yang besar, hampir semua sistem

1104
00:47:10,320 --> 00:47:11,970
yang Anda lihat.

1105
00:47:11,970 --> 00:47:13,146
Apa kebijakannya?

1106
00:47:13,146 --> 00:47:14,270
Atau apa yang menjadi model ancamannya?

1107
00:47:18,300 --> 00:47:22,130
Jadi ini menjadi sedikit bermasalah
dalam banyak sistem di dunia nyata,

1108
00:47:22,130 --> 00:47:23,850
yaitu, bahwa
nyatanya cukup sulit

1109
00:47:23,850 --> 00:47:26,990
untuk menentukan secara tepat apa
aturan atau model ancaman

1110
00:47:26,990 --> 00:47:28,320
yang sedang kita bicarakan.

1111
00:47:28,320 --> 00:47:31,570
Dan ketidaktepatan atau ambiguitas
semacam ini mengenai kebijakan-kebijakan,

1112
00:47:31,570 --> 00:47:33,825
model-model ancaman, dan lain-lain,
adalah yang biasanya

1113
00:47:33,825 --> 00:47:34,950
menimbulkan masalah-masalah keamanan.

1114
00:47:34,950 --> 00:47:37,180
Bukan secara khusus di dalam kasus ini,
tapi kita akan lihat.

1115
00:47:37,180 --> 00:47:40,090
Tapi mungkin hanya untuk memberikan
Anda sebuah gambaran mengenai bagaimana

1116
00:47:40,090 --> 00:47:44,780
cara memikirkan sebuah server web tipikal
di dalam konteks dari kebijakan ini,

1117
00:47:44,780 --> 00:47:47,630
semacam model ancaman, adalah
itu, yah, mungkin kebijakannya

1118
00:47:47,630 --> 00:47:50,005
adalah, server web itu harus melakukan
apa yang pemrogramnya inginkan

1119
00:47:50,005 --> 00:47:50,660
untuk dilakukannya.

1120
00:47:50,660 --> 00:47:51,575
Itu agak tidak jelas.

1121
00:47:51,575 --> 00:47:53,950
Tetapi mungkin itu adalah
yang terjadi, karena apapun yang lebih

1122
00:47:53,950 --> 00:47:55,616
spesifik, juga,
server web itu harus

1123
00:47:55,616 --> 00:47:57,485
melakukan persis sesuai
yang dilakukan kodenya, akan

1124
00:47:57,485 --> 00:47:59,860
menjadi sedikit [TIDAK TERDENGAR]
Dan jika terdapat bug dalam kode Anda,

1125
00:47:59,860 --> 00:48:01,090
yah, kebijakan Anda
mengatakan, yah, itulah

1126
00:48:01,090 --> 00:48:02,131
yang harus saya lakukan.

1127
00:48:02,131 --> 00:48:04,120
Saya harus mengikuti bug tersebut.

1128
00:48:04,120 --> 00:48:07,390
Jadi sedikit sulit untuk menyatakan
sebuah kebijakan dengan tepat,

1129
00:48:07,390 --> 00:48:09,332
tapi dalam kasus ini, mari
pakai saja beberapa versi

1130
00:48:09,332 --> 00:48:11,290
intuitif dari, yah, server
web tersebut harus melakukan apa

1131
00:48:11,290 --> 00:48:13,785
yang pemrogram ingin dia lakukan.

1132
00:48:13,785 --> 00:48:15,160
Dan model ancamannya
kemungkinan berupa,

1133
00:48:15,160 --> 00:48:18,260
sang penyerang tidak memiliki
akses ke komputer ini,

1134
00:48:18,260 --> 00:48:20,800
tidak bisa masuk secara remote,
tidak memiliki akses secara fisik

1135
00:48:20,800 --> 00:48:22,690
kepadanya, namun bisa mengirim
paket apapun yang mereka mau.

1136
00:48:22,690 --> 00:48:26,874
Jadi mereka tidak terbatas
pada jenis-jenis paket tertentu.

1137
00:48:26,874 --> 00:48:28,290
Apapun yang Anda dapat
bentuk dan

1138
00:48:28,290 --> 00:48:30,187
kirimkan ke server
web ini, itu sah-sah saja.

1139
00:48:30,187 --> 00:48:32,270
Kelihatan seperti sebuah
model ancaman yang masuk akal, dalam praktek,

1140
00:48:32,270 --> 00:48:34,450
untuk diingat.

1141
00:48:34,450 --> 00:48:39,940
Dan saya rasa tujuannya adalah supaya
server web ini seharusnya tidak

1142
00:48:39,940 --> 00:48:42,752
mengizinkan terjadinya sembarang
hal yang tidak semestinya.

1143
00:48:42,752 --> 00:48:44,460
Saya rasa itu
sesuai dengan apa yang

1144
00:48:44,460 --> 00:48:45,590
dimaksudkan oleh pemrogram.

1145
00:48:45,590 --> 00:48:47,740
Pemrogram mungkin
tidak bermaksud agar permintaan apapun

1146
00:48:47,740 --> 00:48:49,610
dapat mengakses
apapun di server.

1147
00:48:49,610 --> 00:48:51,630
Namun, ternyata jika Anda melakukan
kesalahan-kesalahan tertentu

1148
00:48:51,630 --> 00:48:53,937
dalam menulis perangkat lunak
server web, yang pada dasarnya adalah

1149
00:48:53,937 --> 00:48:55,020
mekanismenya di sini, benar?

1150
00:48:55,020 --> 00:48:57,390
Perangkat lunak server web adalah
sesuatu yang menerima sebuah permintaan

1151
00:48:57,390 --> 00:48:59,050
dan melihatnya dan
memastikan bahwa dia tidak

1152
00:48:59,050 --> 00:49:01,710
akan melakukan sesuatu yang buruk, mengirimkan
sebuah tanggapan balik jika semuanya

1153
00:49:01,710 --> 00:49:02,050
baik-baik saja.

1154
00:49:02,050 --> 00:49:03,424
Server web dalam
mekanisme ini.

1155
00:49:03,424 --> 00:49:05,720
Dia sedang menegakkan kebijakan Anda.

1156
00:49:05,720 --> 00:49:08,730
Dan sebagai hasil, jika perangkat lunak
server webnya bermasalah,

1157
00:49:08,730 --> 00:49:10,270
maka Anda dalam masalah.

1158
00:49:10,270 --> 00:49:12,650
Dan satu jenis masalah
umum, jika Anda sedang

1159
00:49:12,650 --> 00:49:14,670
menulis perangkat lunak dalam
C yang mana, Anda tahu,

1160
00:49:14,670 --> 00:49:16,240
banyak hal yang
masih ditulis dalam C

1161
00:49:16,240 --> 00:49:19,590
dan mungkin akan terus
ditulis dalam C untuk sementara waktu,

1162
00:49:19,590 --> 00:49:21,540
Anda dapat salah mengatur
alokasi memori Anda.

1163
00:49:21,540 --> 00:49:25,330
Dan seperti yang kita sudah lihat dalam
contoh penamaan sertifikat SSL ini,

1164
00:49:25,330 --> 00:49:27,270
bahkan sebuah
byte benar-benar dapat

1165
00:49:27,270 --> 00:49:30,470
membuat sebuah perbedaan besar,
dalam hal apa yang sedang terjadi.

1166
00:49:30,470 --> 00:49:32,480
Dan saya rasa untuk
contoh ini, kita akan

1167
00:49:32,480 --> 00:49:35,960
melihat sebuah potongan kecil dari kode
yang bukan benar-benar server web

1168
00:49:35,960 --> 00:49:36,460
nyata.

1169
00:49:36,460 --> 00:49:38,900
Di dalam lab, Anda akan memiliki
seluruh gambar ini untuk dimainkan.

1170
00:49:38,900 --> 00:49:41,340
Tetapi untuk kuliah, saya
hanya ingin memberikan Anda

1171
00:49:41,340 --> 00:49:43,470
sebuah contoh yang disederhanakan
supaya kita dapat membicarakan

1172
00:49:43,470 --> 00:49:47,140
tentang gambaran dari
inti dari apa yang salah.

1173
00:49:47,140 --> 00:49:51,515
Dan, secara khusus, jika
sistem ini menyala,

1174
00:49:51,515 --> 00:49:56,240
saya akan menunjukkan kepada Anda
semacam fungsi C yang sangat kecil.

1175
00:49:56,240 --> 00:49:59,070
Dan kita dapat semacam
melihat apa yang salah

1176
00:49:59,070 --> 00:50:04,400
jika Anda memberikan masukan yang
berbeda ke potongan kode itu.

1177
00:50:04,400 --> 00:50:05,220
Baiklah.

1178
00:50:05,220 --> 00:50:09,460
Jadi fungsi C yang ada
di pikiran saya adalah ini.

1179
00:50:13,950 --> 00:50:15,920
Di suatu tempat di sini.

1180
00:50:15,920 --> 00:50:16,720
Oh, yah.

1181
00:50:19,684 --> 00:50:21,166
Dia sedang menyala.

1182
00:50:21,166 --> 00:50:23,150
Baiklah.

1183
00:50:23,150 --> 00:50:27,740
Jadi ini adalah semacam
program yang saya bicarakan,

1184
00:50:27,740 --> 00:50:30,280
atau yang saya akan pakai
sebagai contoh di sini.

1185
00:50:30,280 --> 00:50:32,974
Jadi program ini hanya
akan membaca sebuah permintaan.

1186
00:50:32,974 --> 00:50:34,890
Dan Anda dapat semacam
membayangkan dia akan membaca

1187
00:50:34,890 --> 00:50:36,400
sebuah permintaan dari jaringan.

1188
00:50:36,400 --> 00:50:38,462
Tapi untuk tujuan
dari contoh ini,

1189
00:50:38,462 --> 00:50:40,420
dia hanya akan membaca
sebuah permintaan dari apapun

1190
00:50:40,420 --> 00:50:42,940
yang saya ketik di keyboard.

1191
00:50:42,940 --> 00:50:45,425
Dan dia akan menyimpannya
di dalam sebuah buffer di sini.

1192
00:50:45,425 --> 00:50:47,300
Kemudian dia akan menguraikannya
menjadi sebuah bilangan bulat

1193
00:50:47,300 --> 00:50:48,470
dan mengembalikan bilangan bulat itu.

1194
00:50:48,470 --> 00:50:52,430
Lalu program tersebut akan mencetak
bilangan bulat apapun yang saya dapatkan.

1195
00:50:52,430 --> 00:50:54,110
Ini masih jauh dari server web.

1196
00:50:54,110 --> 00:50:57,290
Tetapi kita setidaknya akan
melihat beberapa hal dasar

1197
00:50:57,290 --> 00:51:00,920
dari bagaimana buffer oveflow bekerja dan
apa yang tidak berjalan dengan semestinya.

1198
00:51:00,920 --> 00:51:03,380
Jadi marilah kita melihat apa yang
terjadi ketika kita menjalankan program ini.

1199
00:51:03,380 --> 00:51:05,875
Jadi saya dapat meng-compile-nya di sini.

1200
00:51:05,875 --> 00:51:07,250
Dan sebenarnya, Anda
seperti dapat melihat

1201
00:51:07,250 --> 00:51:10,600
-- dia sudah memberitahu saya
apa yang saya kacaukan, benar?

1202
00:51:10,600 --> 00:51:13,535
Fungsi get ini berbahaya
dan tidak boleh digunakan.

1203
00:51:13,535 --> 00:51:15,710
Dan kita akan melihat sebentar
lagi mengapa compilernya

1204
00:51:15,710 --> 00:51:18,300
sangat ingin memberitahukan ini kepada saya.

1205
00:51:18,300 --> 00:51:20,320
Dan dia memang benar.

1206
00:51:20,320 --> 00:51:23,530
Tetapi untuk sekarang, anggap saja
kita adalah pengembang yang

1207
00:51:23,530 --> 00:51:26,660
selalu senang, tak pernah risau dan
bersedia mengabaikan peringatan ini.

1208
00:51:26,660 --> 00:51:27,350
Jadi oke.

1209
00:51:27,350 --> 00:51:30,200
Saya menjalankan fungsi pengalihan ini,
saya memberikan beberapa masukan,

1210
00:51:30,200 --> 00:51:33,040
dan berhasil.

1211
00:51:33,040 --> 00:51:34,900
Mari kita lihat kalau saya
memberi masukan-masukan yang besar.

1212
00:51:34,900 --> 00:51:37,265
Jika saya mengetik beberapa
bilangan besar, yah,

1213
00:51:37,265 --> 00:51:38,890
setidaknya dia memberi saya
suatu bilangan yang besar.

1214
00:51:38,890 --> 00:51:43,000
Dia pada dasarnya akan memaksimalkan ke
dua pangkat 31 lalu mencetak angka itu

1215
00:51:43,000 --> 00:51:44,530
dan tidak akan menjadi lebih tinggi lagi.

1216
00:51:44,530 --> 00:51:46,290
Jadi itu mungkin tidak akan
menjadi bencana, benar?

1217
00:51:46,290 --> 00:51:46,790
Terserah.

1218
00:51:46,790 --> 00:51:49,570
Anda memberi bilangan
yang luar biasa besar ini.

1219
00:51:49,570 --> 00:51:51,990
Anda punya sesuatu
yang tidak cukup berhasil.

1220
00:51:51,990 --> 00:51:53,510
Itu belum benar-benar menjadi masalah.

1221
00:51:53,510 --> 00:51:55,520
Tetapi jika kita memberikan
beberapa masukan yang sangat besar,

1222
00:51:55,520 --> 00:51:57,880
Kita mungkin akan mendapatkan
masalah lain, benar?

1223
00:51:57,880 --> 00:52:00,940
Jadi misalkan saya memberikan
lebih dari 12 data

1224
00:52:00,940 --> 00:52:03,395
Saya baru saja memasukkan banyak hal
yang bukan merupakan angka.

1225
00:52:03,395 --> 00:52:04,020
Dia menampilkan nol.

1226
00:52:04,020 --> 00:52:06,430
Itu tidak terlalu buruk.

1227
00:52:06,430 --> 00:52:10,990
Tapi seandainya saya menuliskan
huruf A dalam jumlah yang banyak.

1228
00:52:10,990 --> 00:52:13,490
Oke, jadi sekarang programnya crash.

1229
00:52:13,490 --> 00:52:14,770
Mungkin tidak terlalu mengejutkan.

1230
00:52:14,770 --> 00:52:18,115
Jadi kalau kasusnya adalah ketika saya
mengirim sebuah permintaan yang buruk ke

1231
00:52:18,115 --> 00:52:20,740
server web, dia tidak merespon
saya atau tidak mengirim balasan,

1232
00:52:20,740 --> 00:52:21,629
maka itu tidak masalah.

1233
00:52:21,629 --> 00:52:23,170
Tapi kita akan semacam
memandang ke dalam dan melihat

1234
00:52:23,170 --> 00:52:25,750
apa yang terjadi, dan mencoba untuk
mencari tahu bagaimana cara kita bisa

1235
00:52:25,750 --> 00:52:30,610
memanfaatkan crash ini untuk barangkali
melakukan sesuatu yang jauh lebih

1236
00:52:30,610 --> 00:52:35,960
menarik, atau, yah, jauh lebih sesuai
dengan apa yang seorang hacker mungkin

1237
00:52:35,960 --> 00:52:37,794
tertarik untuk melakukannya.

1238
00:52:37,794 --> 00:52:39,710
Jadi untuk melakukan ini, kita
akan menjalankan program ini

1239
00:52:39,710 --> 00:52:40,680
di dalam sebuah debugger.

1240
00:52:40,680 --> 00:52:43,980
Anda akan sangat terbiasa
dengan ini dalam lab satu.

1241
00:52:43,980 --> 00:52:45,500
Tapi untuk sekarang, apa
yang kita akan lakukan

1242
00:52:45,500 --> 00:52:49,700
adalah memasang sebuah breakpoint (titik berhenti)
dalam fungsi pengalihan itu.

1243
00:52:49,700 --> 00:52:52,380
Dan kita akan menyusuri
bersama dan melihat apa yang terjadi.

1244
00:52:52,380 --> 00:52:54,410
Jadi ketika saya menjalankan
programnya, dia akan

1245
00:52:54,410 --> 00:52:56,450
mulai jalan di
dalam fungsi main.

1246
00:52:56,450 --> 00:52:58,780
Dan cukup cepat,
dia memanggil pengalihan (redirect).

1247
00:52:58,780 --> 00:53:01,790
Dan debuggernya sekarang berhenti
di awal pengalihan.

1248
00:53:01,790 --> 00:53:06,830
Dan kita benar-benar dapat melihat apa yang
sedang terjadi di sini dengan, misalnya,

1249
00:53:06,830 --> 00:53:09,455
kita dapat memintanya untuk mencetak
register-register CPU saat ini.

1250
00:53:09,455 --> 00:53:11,330
Kita akan melihat hal-hal
dengan level yang sangat rendah

1251
00:53:11,330 --> 00:53:13,610
di sini, berlawanan dengan
tingkat kode sumber dari bahasa C.

1252
00:53:13,610 --> 00:53:15,090
Kita akan melihat instruksi-
instruksi yang sebenarnya

1253
00:53:15,090 --> 00:53:16,881
yang dijalankan oleh
komputer saya karena itulah

1254
00:53:16,881 --> 00:53:17,930
yang sebenarnya sedang terjadi.

1255
00:53:17,930 --> 00:53:20,950
C sebenarnya mungkin sedang
menyembunyikan beberapa hal dari kita.

1256
00:53:20,950 --> 00:53:23,110
Jadi Anda dapat benar-benar
mencetak seluruh register.

1257
00:53:23,110 --> 00:53:25,974
Jadi di x86, seperti yang
mungkin Anda ingat.

1258
00:53:25,974 --> 00:53:27,390
Yah, pada arsitektur
[TIDAK TERDENGAR],

1259
00:53:27,390 --> 00:53:29,170
ada sebuah penunjuk stack.

1260
00:53:29,170 --> 00:53:32,530
Jadi biarkan saya mulai menggambar
diagram ini pada papan

1261
00:53:32,530 --> 00:53:36,450
sehingga kita dapat mencoba untuk
merekonstruksi apa yang terjadi.

1262
00:53:36,450 --> 00:53:39,550
Jadi apa yang sedang terjadi adalah
program saya, secara tidak mengherankan,

1263
00:53:39,550 --> 00:53:41,020
memiliki sebuah stack.

1264
00:53:41,020 --> 00:53:43,300
Pada x86, stack turun ke bawah.

1265
00:53:43,300 --> 00:53:46,040
Jadi itu adalah semacam
stack seperti ini.

1266
00:53:46,040 --> 00:53:49,020
Dan kita dapat terus
memasukkan barang ke dalamnya.

1267
00:53:49,020 --> 00:53:51,980
Jadi sekarang,
penunjuk stacknya menunjuk

1268
00:53:51,980 --> 00:53:58,230
pada lokasi memori
yang khusus ini FFD010.

1269
00:53:58,230 --> 00:53:59,535
Jadi dengan nilai tertentu.

1270
00:53:59,535 --> 00:54:01,660
Jadi Anda dapat mencoba untuk mencari
tahu, bagaimana dia sampai di sana?

1271
00:54:01,660 --> 00:54:05,480
Salah satu cara untuk melakukannya
adalah dengan membongkar kode

1272
00:54:05,480 --> 00:54:07,380
dari fungsi pengalihan ini.

1273
00:54:12,650 --> 00:54:14,230
Apakah ini akan bekerja dengan lebih baik?

1274
00:54:14,230 --> 00:54:15,620
Betulkah?

1275
00:54:15,620 --> 00:54:18,250
Variabel pembantu harus
bernilai bilangan bulat.

1276
00:54:20,870 --> 00:54:21,370
Astaga.

1277
00:54:21,370 --> 00:54:22,786
Apa yang terjadi
dengan debugger saya?

1278
00:54:28,190 --> 00:54:28,690
Baiklah.

1279
00:54:28,690 --> 00:54:31,500
Nah, kita dapat membongkar
fungsinya berdasarkan nama.

1280
00:54:31,500 --> 00:54:33,200
Jadi inilah yang sedang
dilakukan oleh fungsinya.

1281
00:54:33,200 --> 00:54:36,340
Jadi pertama-tama, dia memulai
dengan memanipulasi sesuatu

1282
00:54:36,340 --> 00:54:37,362
dengan register EBP ini.

1283
00:54:37,362 --> 00:54:38,570
Itu tidak terlalu menarik.

1284
00:54:38,570 --> 00:54:40,620
Tapi hal pertama yang
dilakukannya setelah itu adalah

1285
00:54:40,620 --> 00:54:43,800
mengurangi nilai tertentu
dari penunjuk stack.

1286
00:54:43,800 --> 00:54:46,940
Ini adalah, pada dasarnya, dia sedang
membuat ruang untuk seluruh variabel itu,

1287
00:54:46,940 --> 00:54:50,680
seperti buffer dan bilangan bulat,
i, yang kita lihat dalam kode sumber C.

1288
00:54:50,680 --> 00:54:53,570
Jadi kita sebenarnya,
sekarang, sudah empat instruksi

1289
00:54:53,570 --> 00:54:55,230
ke dalam fungsi, di sini.

1290
00:54:55,230 --> 00:54:57,190
Jadi nilai penunjuk
stack itu yang kita

1291
00:54:57,190 --> 00:55:01,560
lihat sebelumnya sebenarnya sudah
berada di tengah, jadi dapat dibilang,

1292
00:55:01,560 --> 00:55:02,730
dari stack itu.

1293
00:55:02,730 --> 00:55:06,840
Dan sekarang,
terdapat beberapa hal di atasnya

1294
00:55:06,840 --> 00:55:09,550
yang akan menjadi
buffer, nilai bilangan bulat

1295
00:55:09,550 --> 00:55:12,110
itu, dan sebenarnya, juga
alamat kembali (return address)

1296
00:55:12,110 --> 00:55:14,390
menuju ke fungsi main
masuk ke dalam stack, juga.

1297
00:55:14,390 --> 00:55:17,734
Jadi di suatu tempat di sini, kita akan
memiliki alamat kembalinya.

1298
00:55:17,734 --> 00:55:19,150
Dan kita sebenarnya
mencoba untuk mencari tahu,

1299
00:55:19,150 --> 00:55:20,720
di mana letak hal-hal dalam stack itu?

1300
00:55:20,720 --> 00:55:26,850
Jadi kita dapat mencetak alamat
dari variabel buffer itu.

1301
00:55:26,850 --> 00:55:31,040
Jadi variabel buffer itu
berada di alamat D02C.

1302
00:55:31,040 --> 00:55:35,690
Kita juga dapat mencetak
nilai dari bilangan bulat itu, i.

1303
00:55:35,690 --> 00:55:38,960
Dia berada di D0AC.

1304
00:55:38,960 --> 00:55:40,970
Jadi i tersebut berada jauh di atas dalam stack.

1305
00:55:40,970 --> 00:55:44,310
Tapi buffernya sedikit lebih bawah.

1306
00:55:44,310 --> 00:55:47,210
Jadi apa yang sedang terjadi adalah bahwa
kita memiliki buffer kita di sini

1307
00:55:47,210 --> 00:55:52,460
dalam stack, dan kemudian diikuti
oleh i di atasnya dan mungkin

1308
00:55:52,460 --> 00:55:54,640
beberapa hal lainnya, dan
pada akhirnya, alamat

1309
00:55:54,640 --> 00:55:57,260
kembali menuju fungsi main
yang memanggil pengalihan.

1310
00:55:57,260 --> 00:56:00,910
Dan buffernya
adalah-- ini berjalan,

1311
00:56:00,910 --> 00:56:02,290
stacknya memanjang ke bawah.

1312
00:56:02,290 --> 00:56:03,845
Jadi ini adalah alamat-alamat yang lebih tinggi.

1313
00:56:07,250 --> 00:56:11,010
Jadi apa yang dimaksud adalah bahwa
buffernya-- kita sebenarnya

1314
00:56:11,010 --> 00:56:13,750
perlu menentukan, di mana elemen
ke-nol dari buffer berada,

1315
00:56:13,750 --> 00:56:16,950
dan di mana elemen ke-128
dari buffer ini berada?

1316
00:56:16,950 --> 00:56:20,510
Jadi di mana elemen ke-nol
dari buffer itu berada?

1317
00:56:20,510 --> 00:56:22,205
Ya?

1318
00:56:22,205 --> 00:56:24,080
Seharusnya berada di bawah,
benar, karena ya,

1319
00:56:24,080 --> 00:56:25,590
elemen yang lebih tinggi
akan terus naik atas.

1320
00:56:25,590 --> 00:56:27,505
Jadi buff ke-nol berada di bawah sini.

1321
00:56:27,505 --> 00:56:28,760
Itu akan tetap berjalan terus.

1322
00:56:28,760 --> 00:56:31,140
Dan buff ke-127 akan
berada di atas sana.

1323
00:56:31,140 --> 00:56:34,240
Dan kemudian kita akan memiliki
i dan benda-benda lainnya.

1324
00:56:34,240 --> 00:56:35,020
Oke.

1325
00:56:35,020 --> 00:56:36,860
Nah, mari kita lihat apa yang
akan terjadi jika kita

1326
00:56:36,860 --> 00:56:39,620
memberi input itu yang tadi
sepertinya menyebabkan crash.

1327
00:56:39,620 --> 00:56:41,120
Jadi saya kira hal yang
sebenarnya bisa kita

1328
00:56:41,120 --> 00:56:43,700
lakukan sebelum ini adalah
melihat apakah kita bisa

1329
00:56:43,700 --> 00:56:45,270
menemukan alamat kembali ini.

1330
00:56:45,270 --> 00:56:48,870
Dia sebenarnya berada
pada penunjuk EBP.

1331
00:56:48,870 --> 00:56:52,700
Ini hanyalah sebuah hal yang praktis
dalam konvensi pemanggilan x86,

1332
00:56:52,700 --> 00:56:59,270
bahwa penunjuk EBP tersebut,
atau register, sebenarnya

1333
00:56:59,270 --> 00:57:02,150
kebetulan menunjuk kepada sesuatu
dalam stack yang akan

1334
00:57:02,150 --> 00:57:06,040
disebut EBP tersimpan (saved EBP).

1335
00:57:06,040 --> 00:57:08,870
Lokasinya terpisah, kurang
lebih setelah semua variabel

1336
00:57:08,870 --> 00:57:10,250
tetapi sebelum alamat kembalinya.

1337
00:57:10,250 --> 00:57:11,666
Dan ini merupakan
sesuatu yang sedang

1338
00:57:11,666 --> 00:57:14,800
disimpan oleh beberapa
instruksi awal di atas.

1339
00:57:14,800 --> 00:57:16,630
Dan Anda sebenarnya
semacam memeriksanya.

1340
00:57:16,630 --> 00:57:23,450
Dalam GDB Anda dapat mengatakan, periksa x,
nilai tertentu, jadi nilai dari

1341
00:57:23,450 --> 00:57:24,570
penunjuk EBP.

1342
00:57:24,570 --> 00:57:26,720
Jadi itu adalah lokasi
dari stack tersebut, D0B8.

1343
00:57:26,720 --> 00:57:30,020
Memang, dia ternyata berada
bahkan di atas variabel i.

1344
00:57:30,020 --> 00:57:30,770
Jadi itu bagus.

1345
00:57:30,770 --> 00:57:32,436
Dan dia memiliki beberapa
nilai lain yang ternyata

1346
00:57:32,436 --> 00:57:36,050
merupakan EBP sebelum
fungsi ini dipanggil.

1347
00:57:36,050 --> 00:57:38,950
Tetapi kemudian, semacam satu
lagi lokasi memori

1348
00:57:38,950 --> 00:57:40,710
di atasnya akan menjadi
alamat kembalinya.

1349
00:57:40,710 --> 00:57:44,210
Jadi jika kita mencetak EBP ditambah empat,
ada sesuatu yang lain di sana,

1350
00:57:44,210 --> 00:57:48,800
yaitu 0x08048E5F ini.

1351
00:57:48,800 --> 00:57:51,720
Dan marilah kita
melihat ke mana dia menunjuk.

1352
00:57:51,720 --> 00:57:54,485
Jadi ini merupakan sesuatu yang
akan banyak Anda lakukan dalam lab.

1353
00:57:54,485 --> 00:57:56,140
Jadi Anda dapat mengambil alamat ini.

1354
00:57:56,140 --> 00:57:59,070
Dan Anda dapat mencoba
untuk membongkarnya.

1355
00:57:59,070 --> 00:58:00,130
Lalu siapakah orang ini?

1356
00:58:00,130 --> 00:58:02,290
Di manakah kita akan berakhir?

1357
00:58:02,290 --> 00:58:05,040
Jadi GDP dapat membantu untuk
menentukan fungsi mana

1358
00:58:05,040 --> 00:58:06,480
yang berisi alamat tersebut.

1359
00:58:06,480 --> 00:58:07,640
Jadi 5F.

1360
00:58:07,640 --> 00:58:11,550
Inilah orang yang ditunjuk
oleh alamat kembali kita.

1361
00:58:11,550 --> 00:58:13,790
Dan seperti yang Anda bisa lihat,
ini adalah instruksi tepat

1362
00:58:13,790 --> 00:58:16,070
setelah panggilan untuk pengalihan.

1363
00:58:16,070 --> 00:58:17,655
Jadi ketika kita kembali
dari pengalihan, ini

1364
00:58:17,655 --> 00:58:20,570
adalah lokasi persis yang kita akan
tuju untuk melanjutkan eksekusi.

1365
00:58:20,570 --> 00:58:22,319
Ini adalah, mudah-mudahan,
hal-hal yang cukup lugas

1366
00:58:22,319 --> 00:58:25,660
dari 004, sejenis kelas
sistem operasi standar.

1367
00:58:25,660 --> 00:58:26,160
Oke.

1368
00:58:26,160 --> 00:58:28,300
Jadi di mana kita berada sekarang?

1369
00:58:28,300 --> 00:58:33,060
Hanya untuk merekap, kita dapat
mencoba untuk membongkar penunjuk

1370
00:58:33,060 --> 00:58:33,990
instruksi kita.

1371
00:58:33,990 --> 00:58:36,900
Jadi kita berada di permulaan
pengalihan sekarang.

1372
00:58:36,900 --> 00:58:43,520
Dan kita bisa menjalankannya sedikit, dan
mungkin menjalankan fungsi getS() itu.

1373
00:58:43,520 --> 00:58:45,210
Jadi oke, kita menjalankan next.

1374
00:58:45,210 --> 00:58:48,620
Dia menjalankan getS() dan
sekarang sedang menunggu getS()

1375
00:58:48,620 --> 00:58:49,627
untuk kembali.

1376
00:58:49,627 --> 00:58:51,960
Kita bisa memberikan input kita yang
buruk ke getS() and mencoba membuatnya

1377
00:58:51,960 --> 00:58:54,950
crash lagi dan melihat apa yang sedang
terjadi, sebenarnya, di situ, benar?

1378
00:58:54,950 --> 00:58:57,310
Jadi kita dapat menuliskan
sejumlah huruf A lagi.

1379
00:58:57,310 --> 00:58:57,810
Oke.

1380
00:58:57,810 --> 00:59:00,420
Jadi kita sudah keluar dari getS() dan
ternyata keadaannya masih baik-baik saja,

1381
00:59:00,420 --> 00:59:00,919
benar?

1382
00:59:00,919 --> 00:59:02,520
Programnya masih berjalan.

1383
00:59:02,520 --> 00:59:05,830
Tapi kita bisa mencoba mencari tahu,
apa yang ada di dalam memori saat ini

1384
00:59:05,830 --> 00:59:08,775
dan mengapa akan terjadi
hal-hal yang tidak seharusnya.

1385
00:59:08,775 --> 00:59:10,150
Sebenarnya, bagaimana
menurut kalian?

1386
00:59:10,150 --> 00:59:11,025
Apa yang terjadi, betul?

1387
00:59:11,025 --> 00:59:12,980
Jadi saya mencetak banyak huruf A.

1388
00:59:12,980 --> 00:59:14,560
Apa yang getS()
lakukan pada memori?

1389
00:59:16,770 --> 00:59:17,270
Ya, ya.

1390
00:59:17,270 --> 00:59:18,936
Jadi dia terus-menerus menulis
banyak huruf A di sini, betul?

1391
00:59:18,936 --> 00:59:21,360
Yang sebenarnya kita berikan kepada
getS() hanyalah sebuah penunjuk,

1392
00:59:21,360 --> 00:59:23,410
awal dari
alamat ini, betul?

1393
00:59:23,410 --> 00:59:26,660
Jadi ini adalah
argumen untuk getS(),

1394
00:59:26,660 --> 00:59:28,800
adalah sebuah penunjuk ke
lokasi memori ini dalam stack.

1395
00:59:28,800 --> 00:59:30,470
Jadi dia terus menulis banyak huruf A.

1396
00:59:30,470 --> 00:59:32,470
Dan sebenarnya dia tidak
tahu berapa panjangnya,

1397
00:59:32,470 --> 00:59:33,760
jadi dia terus berjalan, betul?

1398
00:59:33,760 --> 00:59:36,334
Dia akan menimpakan huruf-huruf A
terus hingga ke atas stack,

1399
00:59:36,334 --> 00:59:38,500
melewati alamat kembali,
mungkin, dan ke dalam apapun

1400
00:59:38,500 --> 00:59:40,934
yang ada pada stack di atas kita.

1401
00:59:40,934 --> 00:59:42,600
Jadi kita dapat memeriksa
apakah itu kasusnya.

1402
00:59:42,600 --> 00:59:47,064
Jadi kita sebenarnya dapat
mencetak buffernya.

1403
00:59:47,064 --> 00:59:48,480
Dan sebenarnya, itu
memberitahu kita, ya, kita

1404
00:59:48,480 --> 00:59:51,500
memiliki 180 huruf A di
sana, meskipun buffernya

1405
00:59:51,500 --> 00:59:55,670
seharusnya hanya berukuran 128 elemen.

1406
00:59:55,670 --> 00:59:57,310
Jadi ini tidak terlalu bagus.

1407
00:59:57,310 --> 00:59:59,530
Dan kita sebenarnya dapat,
sekali lagi, memeriksa apa

1408
00:59:59,530 --> 01:00:03,290
yang sedang terjadi di penunjuk EBP itu.

1409
01:00:03,290 --> 01:00:05,095
Tanda dolar, EBP.

1410
01:00:05,095 --> 01:00:06,610
Jadi sebenarnya, ya.

1411
01:00:06,610 --> 01:00:12,159
Semuanya adalah 0x41, yang merupakan
pengkodean ASCII dari huruf A.

1412
01:00:12,159 --> 01:00:14,200
Dan sebenarnya, alamat
kembalinya mungkin

1413
01:00:14,200 --> 01:00:15,283
akan mengalami hal yang sama, betul?

1414
01:00:15,283 --> 01:00:19,350
Jika kita mencetak alamat
kembali, itu juga semua huruf A.

1415
01:00:19,350 --> 01:00:20,245
Itu tidak terlalu bagus.

1416
01:00:20,245 --> 01:00:22,370
Bahkan, hal yang akan terjadi
jika kita kembali sekarang adalah

1417
01:00:22,370 --> 01:00:25,447
program akan melompat ke
alamat itu, 41414141.

1418
01:00:25,447 --> 01:00:26,530
Dan tidak ada apa-apa di sana.

1419
01:00:26,530 --> 01:00:27,196
Dan dia akan crash.

1420
01:00:27,196 --> 01:00:29,840
Itulah segmentation fault
yang Anda dapatkan.

1421
01:00:29,840 --> 01:00:33,090
Jadi mari melangkah ke sana
dan melihat apa yang terjadi.

1422
01:00:33,090 --> 01:00:34,490
Jadi mari jalankan perintah next.

1423
01:00:34,490 --> 01:00:37,470
Jadi kita terus melangkah
menyusuri programnya.

1424
01:00:37,470 --> 01:00:40,060
Dan kita dapat melihat di mana kita berada.

1425
01:00:40,060 --> 01:00:40,560
Oke.

1426
01:00:40,560 --> 01:00:43,330
Kita semakin mendekat
ke akhir dari fungsinya.

1427
01:00:43,330 --> 01:00:46,400
Jadi kita dapat melewati
dua instruksi lagi.

1428
01:00:46,400 --> 01:00:49,260
nexti.

1429
01:00:49,260 --> 01:00:51,531
Dan sekarang kita dapat
membongkar kembali.

1430
01:00:51,531 --> 01:00:52,030
Oke.

1431
01:00:52,030 --> 01:00:54,859
Sekarang kita tepat berada pada
perintah kembali dari fungsi ini.

1432
01:00:54,859 --> 01:00:56,150
Dan kita dapat menebaknya.

1433
01:00:56,150 --> 01:00:59,690
Jadi seperti yang Anda bisa
lihat, pada akhir fungsi,

1434
01:00:59,690 --> 01:01:02,120
dia menjalankan instruksi x86
leave (meninggalkan) ini,

1435
01:01:02,120 --> 01:01:05,220
yang pada dasarnya mengembalikan
stack ke tempatnya yang semula.

1436
01:01:05,220 --> 01:01:07,020
Jadi itu seperti menggeser
penunjuk stacknya

1437
01:01:07,020 --> 01:01:10,200
terus hingga kembali ke alamat
kembalinya menggunakan EBP yang sama.

1438
01:01:10,200 --> 01:01:11,810
Itulah tujuan dasarnya.

1439
01:01:11,810 --> 01:01:15,421
Dan sekarang, stacknya sedang
menunjuk pada alamat kembali

1440
01:01:15,421 --> 01:01:16,420
yang akan kita gunakan.

1441
01:01:16,420 --> 01:01:18,340
Dan nyatanya, semua adalah huruf A.

1442
01:01:18,340 --> 01:01:20,370
Jika kita menjalankan
instruksi selanjutnya,

1443
01:01:20,370 --> 01:01:22,730
CPU akan melompat persis ke
alamat memori tersebut

1444
01:01:22,730 --> 01:01:25,350
dan mulai menjalankan kode
di sana dan mengalami crash,

1445
01:01:25,350 --> 01:01:29,160
karena alamat yang berada di
page table itu tidak valid.

1446
01:01:29,160 --> 01:01:32,360
Jadi mari kita lihat, hanya untuk
memeriksa ulang, apa yang terjadi.

1447
01:01:32,360 --> 01:01:34,569
Mari cetak buffer kita lagi.

1448
01:01:34,569 --> 01:01:36,860
Buffer kita-- yah, itu
ternyata cukup menarik,

1449
01:01:36,860 --> 01:01:37,359
benar?

1450
01:01:37,359 --> 01:01:38,930
Jadi sekarang, buffer,
untuk beberapa alasan dia

1451
01:01:38,930 --> 01:01:41,710
hanya menyebutkan huruf A berulang 128 kali.

1452
01:01:41,710 --> 01:01:45,590
Di mana jika Anda mengingat sebelumnya,
dia menyebutkan A diulang 180 kali

1453
01:01:45,590 --> 01:01:47,690
dalam buffer kita.

1454
01:01:47,690 --> 01:01:49,376
Jadi apa yang terjadi?

1455
01:01:49,376 --> 01:01:49,876
Ya?

1456
01:01:49,876 --> 01:01:51,340
AUDIENS: [TIDAK TERDENGAR].

1457
01:01:51,340 --> 01:01:51,695
PROFESSOR: Ya, ya.

1458
01:01:51,695 --> 01:01:52,050
Tepat.

1459
01:01:52,050 --> 01:01:53,633
Jadi sebenarnya ada
sesuatu yang sedang berlangsung

1460
01:01:53,633 --> 01:01:55,160
setelah terjadi
buffer overflow

1461
01:01:55,160 --> 01:01:56,812
yang mengubah keadaannya.

1462
01:01:56,812 --> 01:01:58,270
Jadi sebenarnya, jika
Anda ingat, kita melakukan

1463
01:01:58,270 --> 01:02:00,650
fungsi A to i yang mengkonversi
string menjadi bilangan bulat.

1464
01:02:00,650 --> 01:02:03,070
Dan jika Anda memasukkan
semua huruf A, dia sebenarnya

1465
01:02:03,070 --> 01:02:05,850
menulis nol pada
lokasi memori ini.

1466
01:02:05,850 --> 01:02:08,840
Jadi sebuah nol, jika Anda ingat,
mengakhiri string di C.

1467
01:02:08,840 --> 01:02:12,120
Jadi GDB sekarang berpikir, ya, kita punya
sebuah string yang diakhiri dengan benar

1468
01:02:12,120 --> 01:02:15,155
berupa 128 byte huruf A.

1469
01:02:15,155 --> 01:02:16,780
Tapi Anda tahu, itu
tidak terlalu penting,

1470
01:02:16,780 --> 01:02:18,530
karena kita masih mempunyai
sejumlah huruf A di atas yang

1471
01:02:18,530 --> 01:02:21,180
telah merusak stack kita.

1472
01:02:21,180 --> 01:02:21,680
Oke.

1473
01:02:21,680 --> 01:02:23,554
Itu sebenarnya merupakan
semacam pelajaran penting

1474
01:02:23,554 --> 01:02:25,990
yang-- sebenarnya sedikit
sulit, terkadang,

1475
01:02:25,990 --> 01:02:28,896
untuk menjelajahi buffer overflow
ini karena, meskipun

1476
01:02:28,896 --> 01:02:31,270 
Anda telah mengubah
banyak hal dalam stack,

1477
01:02:31,270 --> 01:02:32,870
Anda masih harus
mencapai suatu titik

1478
01:02:32,870 --> 01:02:34,810
di mana Anda menggunakan
nilai yang Anda sudah, entah bagaimana,

1479
01:02:34,810 --> 01:02:35,700
letakkan pada stack.

1480
01:02:35,700 --> 01:02:37,140
Jadi ada kode
lain yang

1481
01:02:37,140 --> 01:02:38,940
akan berjalan setelah
Anda berhasil meng-overflow

1482
01:02:38,940 --> 01:02:40,274
beberapa buffer dan merusak memori.

1483
01:02:40,274 --> 01:02:42,690
Anda harus memastikan kalau
kode tersebut tidak melakukan hal bodoh

1484
01:02:42,690 --> 01:02:45,490
seperti, jika itu adalah fungsi
A to i, langsung saja keluar,

1485
01:02:45,490 --> 01:02:48,070
segera setelah dia melihat sebuah
nilai yang bukan bilangan bulat,

1486
01:02:48,070 --> 01:02:53,350
kita mungkin tidak dapat melompat
ke semua alamat 41414141 ini.

1487
01:02:53,350 --> 01:02:55,419
Jadi Anda harus mengatur
masukan Anda dalam beberapa kasus.

1488
01:02:55,419 --> 01:02:56,710
Mungkin tidak demikian dalam kasus ini.

1489
01:02:56,710 --> 01:02:58,470
Tetapi dalam situasi-situasi
lain, Anda harus

1490
01:02:58,470 --> 01:03:01,110
berhati-hati dalam
membuat masukan ini.

1491
01:03:01,110 --> 01:03:04,655
Oke, agar kita melihat apa yang terjadi,
kita bisa melangkah sekali lagi

1492
01:03:04,655 --> 01:03:06,030
Ya, mari kita lihat
ke dalam register kita.

1493
01:03:06,030 --> 01:03:10,400
Jadi sekarang, EIP kita, yang
adalah semacam penunjuk instruksi

1494
01:03:10,400 --> 01:03:12,780
yang menunjuk kepada hal
terakhir dalam pengalihan.

1495
01:03:12,780 --> 01:03:14,830
Dan jika kita melangkah sekali
lagi, harapannya kita akan

1496
01:03:14,830 --> 01:03:19,570
melompat ke, akhirnya,
alamat 4141 yang malang itu.

1497
01:03:19,570 --> 01:03:20,120
Di sini.

1498
01:03:20,120 --> 01:03:20,987
Dan nyatanya, ya.

1499
01:03:20,987 --> 01:03:22,820
Programnya terlihat
sedang berjalan di sana.

1500
01:03:22,820 --> 01:03:25,990
Jika kita meminta GDB untuk
mencetak seluruh register saat ini,

1501
01:03:25,990 --> 01:03:29,420
ya, penunjuk instruksinya
saat ini adalah nilai aneh ini.

1502
01:03:29,420 --> 01:03:31,840
Dan jika kita mengecualikan
satu instruksi lagi,

1503
01:03:31,840 --> 01:03:34,200
dia akan crash
karena akhirnya dia

1504
01:03:34,200 --> 01:03:39,700
mencoba menjalankan sebuah
penunjuk perintah yang tidak sesuai

1505
01:03:39,700 --> 01:03:42,730
dengan sebuah page yang sah
dalam tabel halaman sistem operasi

1506
01:03:42,730 --> 01:03:44,770
untuk proses ini.

1507
01:03:44,770 --> 01:03:46,750
Masuk akal?

1508
01:03:46,750 --> 01:03:49,260
Apakah ada pertanyaan?

1509
01:03:49,260 --> 01:03:49,760
Baiklah.

1510
01:03:49,760 --> 01:03:52,910
Ya, saya sebenarnya memiliki
sebuah pertanyaan untuk kalian.

1511
01:03:52,910 --> 01:03:58,540
Jadi apa yang akan terjadi-- Anda
tahu, itu terlihat dapat dieksploitasi.

1512
01:03:58,540 --> 01:03:59,644
Atau yah, oke.

1513
01:03:59,644 --> 01:04:02,060
Mungkin lebih baik kita mencari
tahu dulu mengapa hal ini buruk,

1514
01:04:02,060 --> 01:04:02,560
benar?

1515
01:04:02,560 --> 01:04:03,762
Jadi mengapa hal ini merupakan sebuah masalah?

1516
01:04:03,762 --> 01:04:05,220
Jadi tidak hanya program
kita mengalami crash,

1517
01:04:05,220 --> 01:04:07,011
tetapi mungkin kita juga akan
mengambil alih kendalinya.

1518
01:04:07,011 --> 01:04:09,010
Jadi saya kira, pertanyaan
sederhana pertama adalah, oke,

1519
01:04:09,010 --> 01:04:10,474
jadi apa masalahnya?

1520
01:04:10,474 --> 01:04:11,140
Apa yang dapat Anda lakukan?

1521
01:04:11,140 --> 01:04:11,890
Ya?

1522
01:04:11,890 --> 01:04:13,180
AUDIENS: Anda dapat melakukan
apapun yang Anda mau.

1523
01:04:13,180 --> 01:04:13,846
PROFESSOR: Ya.

1524
01:04:13,846 --> 01:04:16,809
Jadi tadi saya cukup konyol dan
hanya memasukkan banyak huruf A.

1525
01:04:16,809 --> 01:04:18,350
Tapi jika Anda berhati-hati
dalam mengetahui

1526
01:04:18,350 --> 01:04:20,512
di mana harus menempatkan
nilai apa, Anda mungkin

1527
01:04:20,512 --> 01:04:21,970
bisa memasukkan
nilai yang berbeda

1528
01:04:21,970 --> 01:04:23,387
dan membuatnya melompat
ke tempat yang lain.

1529
01:04:23,387 --> 01:04:25,344
Jadi mari kita lihat apakah kita
memang bisa melakukan hal ini, benar?

1530
01:04:25,344 --> 01:04:26,710
Kita bisa menelusuri ulang benda ini.

1531
01:04:26,710 --> 01:04:27,210
Oke.

1532
01:04:27,210 --> 01:04:28,930
Jalankan kembali programnya.

1533
01:04:28,930 --> 01:04:33,030
Dan saya kira saya harus
mereset breakpoint-nya.

1534
01:04:33,030 --> 01:04:35,450
Jadi saya bisa berhenti
dan mengalihkan lagi.

1535
01:04:35,450 --> 01:04:36,570
Dan menjalankannya.

1536
01:04:36,570 --> 01:04:42,000
Dan kali ini, saya akan,
kembali, berikutnya,

1537
01:04:42,000 --> 01:04:43,900
memberikan banyak huruf A
dan memicu terjadinya overflow.

1538
01:04:43,900 --> 01:04:47,980
Tapi saya tidak akan mencoba
untuk secara hati-hati membangun--

1539
01:04:47,980 --> 01:04:50,445
Anda tahu, mencari tahu titik mana
dalam huruf-huruf A ini yang bersesuaian

1540
01:04:50,445 --> 01:04:51,710
dengan lokasi itu dalam stack.

1541
01:04:51,710 --> 01:04:52,430
Itu adalah sesuatu
yang kalian harus

1542
01:04:52,430 --> 01:04:53,920
lakukan untuk lab satu.

1543
01:04:53,920 --> 01:04:57,050
Tapi misalkan saya
meng-overflow stacknya di sini.

1544
01:04:57,050 --> 01:04:58,470
Dan kemudian saya akan
mencoba secara manual

1545
01:04:58,470 --> 01:05:01,470
untuk mengubah hal-hal dalam stack
untuk membuatnya melompat ke beberapa titik

1546
01:05:01,470 --> 01:05:03,310
yang saya ingin tuju.

1547
01:05:03,310 --> 01:05:08,979
Dan pada program ini, oke,
mari kita sekali lagi-- nexti.

1548
01:05:08,979 --> 01:05:09,520
Di mana kita?

1549
01:05:09,520 --> 01:05:12,350
Kita berada, sekali lagi, di
akhir dari pengalihan.

1550
01:05:12,350 --> 01:05:14,540
Dan mari kita lihat
stacknya, benar?

1551
01:05:14,540 --> 01:05:18,420
Jika kita memeriksa esp di sini, kita
melihat pointer kita yang telah rusak.

1552
01:05:18,420 --> 01:05:18,920
Oke.

1553
01:05:18,920 --> 01:05:21,020
Ke mana kita bisa melompat?

1554
01:05:21,020 --> 01:05:22,794
Hal yang menarik apa
yang dapat kita lakukan?

1555
01:05:22,794 --> 01:05:24,710
Sayangnya, program
ini cukup terbatas.

1556
01:05:24,710 --> 01:05:26,543
Hampir tidak ada apa-apa
dalam kode program tersebut

1557
01:05:26,543 --> 01:05:28,880
di mana Anda dapat menuju ke sana
dan melakukan sesuatu yang menarik.

1558
01:05:28,880 --> 01:05:31,350
Tetapi mungkin kita dapat melakukan
sedikit hal yang menarik.

1559
01:05:31,350 --> 01:05:33,460
Mungkin kita akan mencari
printf dalam main

1560
01:05:33,460 --> 01:05:36,190
dan melompat langsung ke sana, dan
membuatnya mencetak nilai x,

1561
01:05:36,190 --> 01:05:37,710
atau x sama dengan sesuatu.

1562
01:05:37,710 --> 01:05:38,590
Jadi kita dapat melakukan ini.

1563
01:05:38,590 --> 01:05:41,820
Kita sebenarnya dapat membongkar
fungsi main tersebut.

1564
01:05:41,820 --> 01:05:44,630
And main does a
bunch of stuff, you

1565
01:05:44,630 --> 01:05:47,710
know, initializes, calls
redirect, does some more stuff,

1566
01:05:47,710 --> 01:05:49,360
and then calls printf.

1567
01:05:49,360 --> 01:05:51,970
So how about we jump to
this point, which is,

1568
01:05:51,970 --> 01:05:54,200
it sets up the
argument to printf,

1569
01:05:54,200 --> 01:05:58,204
which is x equals percent d,
and then actually calls printf.

1570
01:05:58,204 --> 01:05:59,620
So we can actually
take this value

1571
01:05:59,620 --> 01:06:01,900
and try to stick
it in the stack.

1572
01:06:01,900 --> 01:06:05,290
And should be able to do
this with the debugger

1573
01:06:05,290 --> 01:06:06,850
pretty easily, at least.

1574
01:06:06,850 --> 01:06:11,780
So you can do this set
[? int ?] esp equals this value.

1575
01:06:11,780 --> 01:06:14,040
So we can examine esp again
and, indeed, it actually

1576
01:06:14,040 --> 01:06:14,780
has this value.

1577
01:06:14,780 --> 01:06:19,590
So if we continue now,
well, it printed out x

1578
01:06:19,590 --> 01:06:21,950
equals some garbage,
which I guess

1579
01:06:21,950 --> 01:06:24,380
happens to be just whatever
is on the stack that

1580
01:06:24,380 --> 01:06:25,260
was passed to printf.

1581
01:06:25,260 --> 01:06:26,690
We didn't correctly set
up all the arguments

1582
01:06:26,690 --> 01:06:29,065
because we jumped in the middle
of this calling sequence.

1583
01:06:29,065 --> 01:06:30,810
But yeah, we printed this value.

1584
01:06:30,810 --> 01:06:32,790
And then it crashed.

1585
01:06:32,790 --> 01:06:33,650
Why did crash?

1586
01:06:33,650 --> 01:06:36,312
Why do you think?

1587
01:06:36,312 --> 01:06:37,520
What actually happens, right?

1588
01:06:37,520 --> 01:06:40,000
So we jump to printf.

1589
01:06:40,000 --> 01:06:42,085
And then, something went wrong.

1590
01:06:42,085 --> 01:06:42,585
Yeah?

1591
01:06:45,772 --> 01:06:47,230
Well, we changed
the return address

1592
01:06:47,230 --> 01:06:48,930
so that when we
return from redirect,

1593
01:06:48,930 --> 01:06:52,420
we now jump to this new address,
which is that point up there,

1594
01:06:52,420 --> 01:06:53,825
right after printf.

1595
01:06:53,825 --> 01:06:58,160
So where's this
crash coming from?

1596
01:06:58,160 --> 01:06:59,317
Yeah?

1597
01:06:59,317 --> 01:07:01,025
AUDIENCE: Is it
restricted because your i

1598
01:07:01,025 --> 01:07:02,981
is supposed to be some
sort of integer, but--

1599
01:07:02,981 --> 01:07:04,420
PROFESSOR: No, actually,
well the i is like,

1600
01:07:04,420 --> 01:07:05,580
well it's a 32-bit register.

1601
01:07:05,580 --> 01:07:06,790
So whatever's in the
register, it'll print.

1602
01:07:06,790 --> 01:07:08,831
In fact, that's the thing
that's in the register.

1603
01:07:08,831 --> 01:07:10,370
So that's OK.

1604
01:07:10,370 --> 01:07:11,024
Yeah?

1605
01:07:11,024 --> 01:07:12,482
AUDIENCE: [INAUDIBLE]
main returns.

1606
01:07:12,482 --> 01:07:12,935
PROFESSOR: Yes.

1607
01:07:12,935 --> 01:07:13,560
Actually, yeah.

1608
01:07:13,560 --> 01:07:15,525
What's going on is, you
have to sort of-- OK,

1609
01:07:15,525 --> 01:07:17,710
so this is the point
where we jumped.

1610
01:07:17,710 --> 01:07:18,960
It's set up some arguments.

1611
01:07:18,960 --> 01:07:20,115
It actually calls printf.

1612
01:07:20,115 --> 01:07:22,140
printf seems to work.
printf is going to return.

1613
01:07:22,140 --> 01:07:24,584
Now actually, that's fine,
because this call instruction

1614
01:07:24,584 --> 01:07:26,750
put a return address on the
stack for printf to use.

1615
01:07:26,750 --> 01:07:27,810
That's fine.

1616
01:07:27,810 --> 01:07:29,639
Then main is going
to continue running.

1617
01:07:29,639 --> 01:07:31,930
It's going to run the sleeve
instruction, which doesn't

1618
01:07:31,930 --> 01:07:32,929
do anything interesting.

1619
01:07:32,929 --> 01:07:34,454
And then it does another return.

1620
01:07:34,454 --> 01:07:36,120
But the thing in
this-- up to the stack,

1621
01:07:36,120 --> 01:07:38,120
it doesn't actually have
a valid return address.

1622
01:07:38,120 --> 01:07:40,250
So presumably, we
return to some other

1623
01:07:40,250 --> 01:07:42,800
who knows what memory location
that's up on the stack

1624
01:07:42,800 --> 01:07:44,750
and jump somewhere else.

1625
01:07:44,750 --> 01:07:48,010
So unfortunately,
here, our pseudoattack

1626
01:07:48,010 --> 01:07:48,890
didn't really work.

1627
01:07:48,890 --> 01:07:49,840
It ran some code.

1628
01:07:49,840 --> 01:07:51,140
But then it crashed.

1629
01:07:51,140 --> 01:07:52,310
That's probably not
something you want to do.

1630
01:07:52,310 --> 01:07:53,936
So if you really
wanted to be careful,

1631
01:07:53,936 --> 01:07:56,310
you would carefully plant not
just this return address up

1632
01:07:56,310 --> 01:07:58,180
on the stack, but
maybe you'd figure out,

1633
01:07:58,180 --> 01:08:02,270
where is this second red going
to get its return address from,

1634
01:08:02,270 --> 01:08:03,770
and try to carefully
place something

1635
01:08:03,770 --> 01:08:06,100
else on the stack
there that will ensure

1636
01:08:06,100 --> 01:08:08,950
that your program cleanly
exits after it gets exploited

1637
01:08:08,950 --> 01:08:10,892
so that no one notices.

1638
01:08:10,892 --> 01:08:12,350
So this is all
stuff you'll sort of

1639
01:08:12,350 --> 01:08:15,680
try to do in lab one in
a little bit more detail.

1640
01:08:15,680 --> 01:08:20,189
But I guess one thing we
can try to think about now

1641
01:08:20,189 --> 01:08:24,198
is, we sort of understand
why it's bad to jump to the--

1642
01:08:24,198 --> 01:08:25,614
or to have these
buffer overflows.

1643
01:08:31,630 --> 01:08:33,790
One problem, or one sort
of way to think of this

1644
01:08:33,790 --> 01:08:35,939
is that, the problem is just
because the return address is

1645
01:08:35,939 --> 01:08:36,605
up there, right?

1646
01:08:36,605 --> 01:08:38,939
So the buffer keeps
growing and eventually runs

1647
01:08:38,939 --> 01:08:41,149
over the return address.

1648
01:08:41,149 --> 01:08:43,279
What if we flip
the stack around?

1649
01:08:43,279 --> 01:08:47,319
You know, some machines actually
have stacks that grow up.

1650
01:08:47,319 --> 01:08:51,529
So an alternative design
we could sort of imagine

1651
01:08:51,529 --> 01:08:55,370
is one where the stack
starts at the bottom

1652
01:08:55,370 --> 01:08:58,550
and keeps going up
instead of going down.

1653
01:08:58,550 --> 01:09:01,336
So then, if you
overflow this buffer,

1654
01:09:01,336 --> 01:09:02,960
you'll just keep
going up on the stack,

1655
01:09:02,960 --> 01:09:06,576
and maybe there's nothing
bad that will happen.

1656
01:09:06,576 --> 01:09:07,995
Yeah?

1657
01:09:07,995 --> 01:09:10,846
AUDIENCE: [INAUDIBLE].

1658
01:09:10,846 --> 01:09:11,970
PROFESSOR: So you're right.

1659
01:09:11,970 --> 01:09:14,667
It might be that,
if you have-- well,

1660
01:09:14,667 --> 01:09:16,250
so let me draw this
new stack diagram.

1661
01:09:16,250 --> 01:09:20,090
And we'll sort of try to figure
out what it applies to and not.

1662
01:09:20,090 --> 01:09:20,619
But OK.

1663
01:09:20,619 --> 01:09:22,410
So we'll basically just
invert the picture.

1664
01:09:22,410 --> 01:09:25,410
So when you call redirect on
this alternative architecture,

1665
01:09:25,410 --> 01:09:27,300
what's going to happen
is the return address

1666
01:09:27,300 --> 01:09:31,040
is going to go
here on the stack.

1667
01:09:31,040 --> 01:09:34,076
Then we'll have our i variable,
or maybe the saved EBP.

1668
01:09:36,930 --> 01:09:38,620
Then we'll have our i variable.

1669
01:09:38,620 --> 01:09:39,670
And then we'll have buff.

1670
01:09:39,670 --> 01:09:44,660
So we'll have buff of zero,
buff 127, and so on, right?

1671
01:09:44,660 --> 01:09:48,229
So then when we do the overflow,
it overflows up there and maybe

1672
01:09:48,229 --> 01:09:49,310
doesn't hit anything bad.

1673
01:09:49,310 --> 01:09:50,768
I guess what you're
saying is that,

1674
01:09:50,768 --> 01:09:52,595
well, maybe we had
a buffer down there.

1675
01:09:52,595 --> 01:09:54,470
And if we had a buffer
down there, then yeah,

1676
01:09:54,470 --> 01:09:55,761
that seems kind of unfortunate.

1677
01:09:55,761 --> 01:09:58,930
It could overrun
this return address.

1678
01:09:58,930 --> 01:09:59,690
So you're right.

1679
01:09:59,690 --> 01:10:01,420
So you could still
run into problems

1680
01:10:01,420 --> 01:10:03,350
on this stack growing up.

1681
01:10:03,350 --> 01:10:04,785
But what about
this exact program?

1682
01:10:08,420 --> 01:10:11,119
Is this particular
program safe on machines

1683
01:10:11,119 --> 01:10:12,160
where the stack grows up?

1684
01:10:12,160 --> 01:10:15,670
So just to recap what the
program read is this guy.

1685
01:10:18,391 --> 01:10:18,890
Yeah?

1686
01:10:18,890 --> 01:10:19,810
AUDIENCE: Still
going to overwrite

1687
01:10:19,810 --> 01:10:21,190
[INAUDIBLE] as a return value.

1688
01:10:21,190 --> 01:10:21,360
PROFESSOR: Yeah.

1689
01:10:21,360 --> 01:10:22,735
So that's actually
clever, right?

1690
01:10:22,735 --> 01:10:29,040
So this is the stack
frame for redirect.

1691
01:10:29,040 --> 01:10:31,250
I guess it actually spans
all the way up here.

1692
01:10:31,250 --> 01:10:34,790
But what actually happens
when you call getS() is that

1693
01:10:34,790 --> 01:10:36,610
redirect makes a function call.

1694
01:10:36,610 --> 01:10:40,380
It actually saves its return
address up here on the stack.

1695
01:10:40,380 --> 01:10:42,740
And then getS() starts running.

1696
01:10:42,740 --> 01:10:45,490
And getS() puts its
own saved EBP up here.

1697
01:10:45,490 --> 01:10:50,240
And getS() is going to post
its own variables higher up.

1698
01:10:50,240 --> 01:10:54,142
And then getS() is going
to fill in the buffer.

1699
01:10:54,142 --> 01:10:55,350
So this is still problematic.

1700
01:10:55,350 --> 01:10:57,599
Basically, the buffer is
surrounded by return initials

1701
01:10:57,599 --> 01:10:59,430
on all sides.

1702
01:10:59,430 --> 01:11:02,190
Either way, you're going to
be able to overflow something.

1703
01:11:02,190 --> 01:11:06,300
So at what point-- suppose we
had a stack growing up machine.

1704
01:11:06,300 --> 01:11:08,770
At what point would
you be able to take

1705
01:11:08,770 --> 01:11:10,614
control of the program's
execution then?

1706
01:11:14,100 --> 01:11:16,424
Yes, and that is actually
even easier in some ways.

1707
01:11:16,424 --> 01:11:18,340
You don't have to wait
until redirect returns.

1708
01:11:18,340 --> 01:11:20,200
And maybe there was like, stuff
that was going to mess you up

1709
01:11:20,200 --> 01:11:21,210
like this A to i.

1710
01:11:21,210 --> 01:11:21,710
No.

1711
01:11:21,710 --> 01:11:24,281
It's actually easier, because
getS() is going to overflow

1712
01:11:24,281 --> 01:11:24,780
the buffer.

1713
01:11:24,780 --> 01:11:26,480
It's going to change
the return address

1714
01:11:26,480 --> 01:11:28,271
and then immediately
return and immediately

1715
01:11:28,271 --> 01:11:32,440
jump to wherever you sort
of tried to construct,

1716
01:11:32,440 --> 01:11:34,780
makes sense.

1717
01:11:34,780 --> 01:11:38,175
So what happens if we
have a program like this

1718
01:11:38,175 --> 01:11:39,050
that's pretty boring?

1719
01:11:39,050 --> 01:11:41,091
There's like no real
interesting code to jump to.

1720
01:11:41,091 --> 01:11:45,200
All you can do is get it to
print different x values here.

1721
01:11:45,200 --> 01:11:47,504
What if you want to do
something interesting that you

1722
01:11:47,504 --> 01:11:48,645
didn't-- yeah?

1723
01:11:48,645 --> 01:11:52,085
AUDIENCE: I mean, if you
have an extra cable stack,

1724
01:11:52,085 --> 01:11:54,400
you could put
arbitrary code that,

1725
01:11:54,400 --> 01:11:56,027
for example, executes a shell?

1726
01:11:56,027 --> 01:11:57,110
PROFESSOR: Yeah yeah yeah.

1727
01:11:57,110 --> 01:11:59,810
So that's kind of clever,
right, because you actually

1728
01:11:59,810 --> 01:12:01,370
can supply other inputs, right?

1729
01:12:01,370 --> 01:12:04,520
So at least, well-- there's
some defenses against this.

1730
01:12:04,520 --> 01:12:06,700
And we'll go over these
in subsequent lectures.

1731
01:12:06,700 --> 01:12:10,270
But in principle, you could
have the return address here

1732
01:12:10,270 --> 01:12:13,380
that you override on either the
stack up or stack down machine.

1733
01:12:13,380 --> 01:12:16,360
And instead of pointing
it to some existing code,

1734
01:12:16,360 --> 01:12:18,340
like the printf
inside of main, we

1735
01:12:18,340 --> 01:12:22,486
can actually have the return
address point into the buffer.

1736
01:12:22,486 --> 01:12:24,610
So it's previously just
some location on the stack.

1737
01:12:24,610 --> 01:12:27,080
But you could jump there
and treat it as executable.

1738
01:12:27,080 --> 01:12:29,270
So as part of your
request, you'll actually

1739
01:12:29,270 --> 01:12:32,160
send some bytes of
data to the server,

1740
01:12:32,160 --> 01:12:35,690
and then have the return address
or the thing you overwrite here

1741
01:12:35,690 --> 01:12:37,720
point to the base of the
buffer, and you'll just

1742
01:12:37,720 --> 01:12:39,240
keep going from there.

1743
01:12:39,240 --> 01:12:41,429
So then you'll be able
to sort of provide

1744
01:12:41,429 --> 01:12:42,970
the code you want
to run, jump to it,

1745
01:12:42,970 --> 01:12:44,390
and get the server to run it.

1746
01:12:44,390 --> 01:12:46,710
And in fact, traditionally,
in Unix systems,

1747
01:12:46,710 --> 01:12:49,230
what adversaries would often
do is just ask the operating

1748
01:12:49,230 --> 01:12:51,280
system to execute the
binsh command, which

1749
01:12:51,280 --> 01:12:53,390
lets you sort of type in
arbitrary shell commands

1750
01:12:53,390 --> 01:12:54,240
after that.

1751
01:12:54,240 --> 01:12:56,360
So as a result, this
thing, this piece

1752
01:12:56,360 --> 01:12:57,910
of code you inject
into this buffer,

1753
01:12:57,910 --> 01:13:01,260
was often called, sort of for
historical reasons, shell code.

1754
01:13:01,260 --> 01:13:06,420
And you'll try to construct
some in this lab one as well.

1755
01:13:06,420 --> 01:13:07,380
All right.

1756
01:13:07,380 --> 01:13:09,627
Make sense, what
you can do here?

1757
01:13:09,627 --> 01:13:10,210
Any questions?

1758
01:13:10,210 --> 01:13:11,004
Yeah?

1759
01:13:11,004 --> 01:13:13,492
AUDIENCE: Is there a separation
between code and data?

1760
01:13:13,492 --> 01:13:14,200
PROFESSOR: Right.

1761
01:13:14,200 --> 01:13:17,270
So is there a separation
between code and data here?

1762
01:13:17,270 --> 01:13:20,882
At least, well,
historically, many machines

1763
01:13:20,882 --> 01:13:22,840
didn't enforce any
separation of code and data.

1764
01:13:22,840 --> 01:13:24,740
You'd just have a flat
memory address space.

1765
01:13:24,740 --> 01:13:26,290
The stack pointer
points somewhere.

1766
01:13:26,290 --> 01:13:28,322
The code pointer
points somewhere else.

1767
01:13:28,322 --> 01:13:30,780
And you just execute wherever
the code pointer, instruction

1768
01:13:30,780 --> 01:13:32,510
pointer is pointing.

1769
01:13:32,510 --> 01:13:35,000
Modern machines try to
provide some defenses

1770
01:13:35,000 --> 01:13:36,660
for these kinds of attacks.

1771
01:13:36,660 --> 01:13:39,140
And what modern
machines often do is,

1772
01:13:39,140 --> 01:13:40,810
they actually
associate permissions

1773
01:13:40,810 --> 01:13:42,320
with various memory regions.

1774
01:13:42,320 --> 01:13:44,280
And one of the
permissions is execute.

1775
01:13:44,280 --> 01:13:47,730
So the part of your
32-bit or 64-bit address

1776
01:13:47,730 --> 01:13:51,180
space that contains code
has the execute permission.

1777
01:13:51,180 --> 01:13:53,450
So if your instruction
pointer points there,

1778
01:13:53,450 --> 01:13:55,740
the CPU will actually
run those things.

1779
01:13:55,740 --> 01:13:59,057
And the stack and other data
portions of your address space

1780
01:13:59,057 --> 01:14:00,890
typically don't have
the execute permission.

1781
01:14:00,890 --> 01:14:03,610
So if you happen to somehow
set your instruction pointer

1782
01:14:03,610 --> 01:14:07,570
to some non-code memory
location, you can set it,

1783
01:14:07,570 --> 01:14:10,060
but the CPU will
refuse to execute it.

1784
01:14:10,060 --> 01:14:13,930
So this is a reasonably
nice way to defend

1785
01:14:13,930 --> 01:14:15,250
against these kinds of attacks.

1786
01:14:15,250 --> 01:14:18,680
But it doesn't prevent
quite everything.

1787
01:14:18,680 --> 01:14:19,990
So just a question.

1788
01:14:19,990 --> 01:14:20,490
OK.

1789
01:14:20,490 --> 01:14:22,410
So how would you
bypass this if you

1790
01:14:22,410 --> 01:14:24,985
had this non-executable stack?

1791
01:14:24,985 --> 01:14:26,860
You actually saw this
example earlier, right,

1792
01:14:26,860 --> 01:14:30,050
when I actually jumped
to the middle of main.

1793
01:14:30,050 --> 01:14:34,180
So that was a way of sort
of exploiting this buffer

1794
01:14:34,180 --> 01:14:36,820
overflow without having to
inject new code of my own.

1795
01:14:36,820 --> 01:14:39,514
So even if the stack
was non-executable,

1796
01:14:39,514 --> 01:14:41,680
I would still be able to
jump in the middle of main.

1797
01:14:41,680 --> 01:14:43,554
In this particular case,
it's kind of boring.

1798
01:14:43,554 --> 01:14:45,020
It just prints x and crashes.

1799
01:14:45,020 --> 01:14:46,550
But in other
situations, you might

1800
01:14:46,550 --> 01:14:48,090
have other pieces of
code in your program

1801
01:14:48,090 --> 01:14:50,089
that are doing interesting
stuff that you really

1802
01:14:50,089 --> 01:14:51,320
do want to execute.

1803
01:14:51,320 --> 01:14:54,520
And that's sort of called return
to libc attacks for, again,

1804
01:14:54,520 --> 01:14:56,170
somewhat historical reasons.

1805
01:14:56,170 --> 01:14:59,610
But it is a way to bypass
the security measures.

1806
01:14:59,610 --> 01:15:02,860
So in the context
of buffer overflows,

1807
01:15:02,860 --> 01:15:06,699
there's not really
a clear cut solution

1808
01:15:06,699 --> 01:15:08,990
that provides perfect protection
against these mistakes

1809
01:15:08,990 --> 01:15:10,600
because, at the end of the
day, the programmer did

1810
01:15:10,600 --> 01:15:12,310
make some mistake in
writing this source code.

1811
01:15:12,310 --> 01:15:14,540
And the best way to fix it
is probably just to change

1812
01:15:14,540 --> 01:15:17,100
the source code and make sure
you don't call getS() very

1813
01:15:17,100 --> 01:15:18,570
much, like the
compiler warned you.

1814
01:15:18,570 --> 01:15:20,000
And there's more subtle
things that the compiler

1815
01:15:20,000 --> 01:15:20,958
doesn't warn you about.

1816
01:15:20,958 --> 01:15:23,490
And you still have to
avoid making those calls.

1817
01:15:23,490 --> 01:15:26,570
But because it's
hard, in practice,

1818
01:15:26,570 --> 01:15:28,470
to change all the
software out there,

1819
01:15:28,470 --> 01:15:30,080
many people try to
devise techniques

1820
01:15:30,080 --> 01:15:33,100
that make it more difficult
to exploit these bugs.

1821
01:15:33,100 --> 01:15:35,590
For example, making the
stack non-executable,

1822
01:15:35,590 --> 01:15:39,135
so you can't inject the
shell code onto the stack,

1823
01:15:39,135 --> 01:15:41,930
and you have to do something
slightly more elaborate.

1824
01:15:41,930 --> 01:15:45,690
And next couple of
lectures, next two lectures,

1825
01:15:45,690 --> 01:15:47,930
actually, we'll look at
these defense techniques.

1826
01:15:47,930 --> 01:15:48,980
They're not all perfect.

1827
01:15:48,980 --> 01:15:50,480
But they do, in
practice, make it

1828
01:15:50,480 --> 01:15:52,780
much more difficult for that
hacker to exploit things.

1829
01:15:52,780 --> 01:15:53,065
Question?

1830
01:15:53,065 --> 01:15:54,802
AUDIENCE: I just have a general
administrative question.

1831
01:15:54,802 --> 01:15:55,286
PROFESSOR: Yeah?

1832
01:15:55,286 --> 01:15:56,738
AUDIENCE: I was wondering
if there was a final?

1833
01:15:56,738 --> 01:15:58,696
And also if there are
quizzes, and what dates--

1834
01:15:58,696 --> 01:16:00,200
PROFESSOR: Oh yeah.

1835
01:16:00,200 --> 01:16:02,630
Yeah, I think if you go
to the schedule page,

1836
01:16:02,630 --> 01:16:03,960
there's two quizzes.

1837
01:16:03,960 --> 01:16:05,780
And there's no final
during the final week,

1838
01:16:05,780 --> 01:16:08,034
but there's a quiz
right before it.

1839
01:16:08,034 --> 01:16:09,450
So you're free for
the final week,

1840
01:16:09,450 --> 01:16:12,100
but there's still something
at the end of the class.

1841
01:16:12,100 --> 01:16:13,190
Yeah.

1842
01:16:13,190 --> 01:16:14,470
All right.

1843
01:16:14,470 --> 01:16:14,970
OK.

1844
01:16:14,970 --> 01:16:17,310
So I think that's probably
it for buffer overflows.

1845
01:16:17,310 --> 01:16:19,600
I guess the one
question is, so what

1846
01:16:19,600 --> 01:16:21,380
do you do about
mechanism problems?

1847
01:16:21,380 --> 01:16:26,030
And the general answer is to
probably have fewer mechanisms.

1848
01:16:26,030 --> 01:16:27,530
So as we saw here,
if you're relying

1849
01:16:27,530 --> 01:16:29,850
on every piece of software to
enforce your security policy,

1850
01:16:29,850 --> 01:16:31,349
you'll inevitably
have mistakes that

1851
01:16:31,349 --> 01:16:34,110
allow an adversary to bypass
your mechanism to exploit

1852
01:16:34,110 --> 01:16:35,829
some bug in the web server.

1853
01:16:35,829 --> 01:16:37,370
And a much better
design, and one but

1854
01:16:37,370 --> 01:16:39,300
you will explore
in lab two, is one

1855
01:16:39,300 --> 01:16:41,030
where you structure
your whole system

1856
01:16:41,030 --> 01:16:42,621
so the security of
the system doesn't

1857
01:16:42,621 --> 01:16:44,120
depend on all the
pieces of software

1858
01:16:44,120 --> 01:16:45,790
enforcing your security policy.

1859
01:16:45,790 --> 01:16:47,206
The security policy
is going to be

1860
01:16:47,206 --> 01:16:48,970
enforced by a small
number of components.

1861
01:16:48,970 --> 01:16:49,900
And the rest of
the stuff actually

1862
01:16:49,900 --> 01:16:51,483
doesn't matter, for
security purposes,

1863
01:16:51,483 --> 01:16:52,740
if it's right or wrong.

1864
01:16:52,740 --> 01:16:55,060
It's not going to violate
your security policy at all.

1865
01:16:55,060 --> 01:16:58,540
So this, kind of minimizing
your trusted computing base

1866
01:16:58,540 --> 01:17:01,820
is a pretty powerful technique
to get around these mechanism

1867
01:17:01,820 --> 01:17:04,410
bugs and problems that we've
looked at today, at least

1868
01:17:04,410 --> 01:17:05,775
in a little bit of detail.

1869
01:17:05,775 --> 01:17:06,370
All right.

1870
01:17:06,370 --> 01:17:07,620
So read the paper for Monday.

1871
01:17:07,620 --> 01:17:08,828
And come to Monday's lecture.

1872
01:17:08,828 --> 01:17:10,770
And submit the questions
on the website.

1873
01:17:10,770 --> 01:17:12,920
See you guys then.
